{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba: fast 'for' loops in python\n",
    "Author: Pierre Ablin, Mathurin Massias\n",
    "\n",
    "Numba is a Python package that does Just In Time compilation. It can greatly accelerate Python for loops. It implements most Python/Numpy operations.\n",
    "\n",
    "To install it, simply do conda install numba or pip install numba. Be sure to have an up-to-date version:pip install --upgrade numba.\n",
    "\n",
    "First example\n",
    "Say you want to compute $\\sum_{i=1}^n \\frac{1}{i^2}$. The following code does it in pure Python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_python(n):\n",
    "    output = 0.\n",
    "    for i in range(1, n + 1):\n",
    "        output += 1. / i ** 2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.15 ms ± 690 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum_python(10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy\n",
    "To accelerate this loop, you can vectorize it using Numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sum_numpy(n):\n",
    "    return np.sum(1. / np.arange(1, n + 1) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.9 µs ± 1.26 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum_numpy(10000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba\n",
    "You can also use the @njit decorator from Numba. Simply put it on top of the python function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def sum_numba(n):\n",
    "    output = 0.\n",
    "    for i in range(1, n + 1):\n",
    "        output += 1. / i ** 2\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.7 µs ± 1.41 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sum_numba(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orders of magnitude faster than pure Python code, and also (for this example) faster than Numpy !\n",
    "\n",
    "Second example: stochastic gradients\n",
    "Numba can be very handy when coding a stochastic algorithm. Indeed, computing a stochastic gradient can be a very fast operation, hence coding a for loop over it in pure Python can slow the code down.\n",
    "\n",
    "Take the ridge regression $ \\min f(x) = \\frac 1n \\sum_{i=1}^n f_i(x)$ where:\n",
    "\n",
    "$$f_i(x) = \\frac{1}{2}(a_i^\\top x- b_i)^2 + \\frac \\lambda 2 \\|x\\|_2^2$$\n",
    "We have the stochastic gradients: $\\nabla f_i(x) = (a_i^\\top x - b_i) a_i + \\lambda x$, and the full batch gradient: $\\nabla f(x) = \\frac1n A^{\\top}(A x - b) + \\lambda x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, p = 100, 100\n",
    "\n",
    "A = np.random.randn(n, p)\n",
    "b = np.random.randn(n)\n",
    "\n",
    "lam = 0.1\n",
    "x = np.zeros(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_i(x, i, A, b, lam):\n",
    "    ai = A[i]\n",
    "    return (np.dot(ai, x) - b[i]) * ai + lam * x\n",
    "\n",
    "\n",
    "def sgd(x, max_iter, step, A, b, lam):\n",
    "    n, _ = A.shape\n",
    "    for i in range(max_iter):\n",
    "        x -= step * grad_i(x, i % n, A, b, lam)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6 µs ± 137 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit grad_i(x, 0, A, b, lam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3 ms ± 3.85 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sgd(x, 1000, 0.0001, A, b, lam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def grad_i(x, i, A, b, lam):\n",
    "    ai = A[i]\n",
    "    return (np.dot(ai, x) - b[i]) * ai + lam * x\n",
    "\n",
    "\n",
    "@njit\n",
    "def sgd(x, max_iter, step, A, b, lam):\n",
    "    n, _ = A.shape\n",
    "    for i in range(max_iter):\n",
    "        x -= step * grad_i(x, i % n, A, b, lam)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 9.00 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "3.18 µs ± 3.44 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit grad_i(x, 0, A, b, lam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "453 µs ± 11.4 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sgd(x, 1000, 0.0001, A, b, lam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
