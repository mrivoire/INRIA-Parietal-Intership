{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJECT: Course Optimization for Data Science\n",
    "## Optimization strategies for the proportional odds model\n",
    "\n",
    "\n",
    "Author: Alexandre Gramfort\n",
    "\n",
    "If you have questions or if something is not clear in the text below please contact us\n",
    "by email.\n",
    "\n",
    "## Aim:\n",
    "\n",
    "- Derive mathematically and implement the loss and gradients of the proportional odds model\n",
    "- Implement your own solvers for L1 or L2 regularization with: (Accelerated) Proximal gradient descent and L-BFGS (only for L2)\n",
    "- Implement your own scikit-learn estimator for the proportional odds model and test it on the `wine quality` dataset.\n",
    "\n",
    "### Remarks:\n",
    "\n",
    "- This project involves some numerical difficulty due to the presence of many `log` and `exp` functions.\n",
    "- The correct and stable computation of the gradient is quite difficult. For this reason you have the possibility to use the `autograd` package to compute the gradient by automatic differentiation. `autograd` inspired the design of `pytorch`. It is a pure python package which makes it easy to install, and it is sufficient for our usecase.\n",
    "\n",
    "## VERY IMPORTANT\n",
    "\n",
    "This work must be done by pairs of students.\n",
    "Each student must send their work before the 20th of January at 23:59, using the moodle platform.\n",
    "This means that **each student in the pair sends the same file**\n",
    "\n",
    "On the moodle, in the \"Optimization for Data Science\" course, you have a \"devoir\" section called \"Project\".\n",
    "This is where you submit your jupyter notebook file.\n",
    "\n",
    "The name of the file must be constructed as in the next cell\n",
    "\n",
    "### Gentle reminder: no evaluation if you don't respect this EXACTLY\n",
    "\n",
    "#### How to construct the name of your file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_piegard_hadrien_and_benmansour_saphia.ipynb\n"
     ]
    }
   ],
   "source": [
    "# Change here using YOUR first and last names\n",
    "fn1 = \"hadrien\"\n",
    "ln1 = \"piegard\"\n",
    "fn2 = \"saphia\"\n",
    "ln2 = \"benmansour\"\n",
    "\n",
    "filename = \"_\".join(map(lambda s: s.strip().lower(), \n",
    "                        [\"project\", ln1, fn1, \"and\", ln2, fn2])) + \".ipynb\"\n",
    "print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Proportional odds model\n",
    "\n",
    "This model is an ordinal regression model. It is a supervised learning model, in the case where the target space $Y$ is discrete: $Y=\\{1, \\dots, k\\}$; this is the case in multiclass classification for example. Its specificity is that we assume there is an order in the output space. \n",
    "\n",
    "Intuitively, it means that if the true label is 2, predicting 5 is worse that predicting 3 (as 3 is closer to 2 than 5 is). For a usual classification loss, each bad prediction costs the same. In the case of the proportional odds model, **it costs more to predict values that are farther from the true target**.\n",
    "\n",
    "The proportional odds model can be seen as an extension to the logistic regression model as we will see now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with observations in $\\mathbb{R}^p$, the proportional odds model has the following structure for $1 \\leq j \\leq k-1$:\n",
    "\n",
    "$$\n",
    "\\log \\left ( \\frac{P(Y \\leq j \\mid x)}{P(Y > j \\mid x)} \\right ) = \\alpha_j + \\beta^T x ,\n",
    "$$\n",
    "\n",
    "where $\\beta \\in \\mathbb{R}^p$ and $\\alpha = \\{ \\alpha_j \\}_{j=1}^{k-1}$ is an increasing sequence of constants ($\\alpha_1 \\leq \\alpha_2 \\leq \\dots \\leq \\alpha_{k-1}$). We omit here the last term since $P(Y \\leq k) = 1$.\n",
    "Since $P(Y > j | x) = 1 - P(Y \\leq j | x)$, we can rewrite the previous equation as:\n",
    "$$\n",
    "P(Y \\leq j \\mid x) = \\frac{e^{\\alpha_j + \\beta^T x}}{e^{\\alpha_j + \\beta^T x} + 1} = \\phi(\\alpha_j + \\beta^T x)\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "P(Y = j \\mid x) = \\frac{e^{\\alpha_j + \\beta^T x}}{e^{\\alpha_j + \\beta^T x} + 1} - \\frac{e^{\\alpha_{j-1} + \\beta^T x}}{e^{\\alpha_{j-1} + \\beta^T x} + 1} = \\phi(\\alpha_j + \\beta^T x) - \\phi(\\alpha_{j-1} + \\beta^T x)\n",
    "$$\n",
    "\n",
    "for $2 \\leq j \\leq k-1$, where $\\phi$ denotes the sigmoid function $\\phi(t) = 1 / (1 + \\exp(-t))$.\n",
    "\n",
    "After one-hot encoding of the target variable ([`OneHotEncoder`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html), [`LabelBinarizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html)), denoting $\\{ y_{ij} \\}_{j=1}^{k}$ the indicator sequence for the class of the $i^{\\text{th}}$ observation $x_i$ (i.e., exactly one of the $y_{ij}$ equals one and the rest are zero) the negative log likelihood becomes:\n",
    "\n",
    "$$\n",
    "f(\\alpha, \\beta) =\n",
    "- \\sum_{i=1}^{n} \\left [ y_{i1} \\log(\\phi(\\alpha_1 + \\beta^T x_i)) \n",
    "+ \\sum_{j=2}^{k-1} \\Big( y_{ij} \\log( \n",
    "\\phi(\\alpha_j + \\beta^T x_i) - \\phi(\\alpha_{j-1} + \\beta^T x_i)) \\Big)\n",
    "+ y_{ik} \\log(1 - \\phi(\\alpha_{k-1} + \\beta^T x_i)) \\right ] .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introducing some $\\ell_1$ or $\\ell_2$ regularization on the parameter $\\beta$ with regularization parameter $\\lambda \\ge 0$, the penalized likelihood estimation problem reads:\n",
    "$$\n",
    "    (\\mathcal{P}_\\alpha): \\left\\{\n",
    "\t\\begin{aligned}\n",
    "\t\\min_{\\alpha, \\beta} \\quad f(\\alpha, \\beta) + \\lambda \\mathcal{R}(\\beta) \\\\\n",
    "    \\alpha_1 \\leq \\dots \\leq \\alpha_{k-1}\n",
    "\t\\end{aligned}\n",
    "    \\right.\n",
    "$$\n",
    "where $\\mathcal{R}(\\beta) = \\|\\beta\\|_1$ or $\\tfrac{1}{2} \\|\\beta\\|^2_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 1:</b>\n",
    "     <ul>\n",
    "      <li>Justify that $(\\mathcal{P}_\\alpha)$ is a convex problem.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, let's pose g, a real function following:\n",
    "$$ \\forall x \\in \\mathbb{R}, \\; g(x) = log(\\phi(x)) $$\n",
    "\n",
    "Where \n",
    "$$\n",
    "\\phi(\\alpha_j + \\beta^T x) = P(Y \\leq j \\mid x) = \\frac{e^{\\alpha_j + \\beta^T x}}{e^{\\alpha_j + \\beta^T x} + 1}\n",
    "$$\n",
    "\n",
    "So, by denoting\n",
    "$$ \n",
    "\\forall \\beta \\in \\mathbb{{R}^p}, \\alpha_j \\in \\mathbb{R}, \n",
    "X = \\alpha_j + \\beta^T x\n",
    "$$\n",
    "\n",
    "We can calculate the second derivative of g:\n",
    "$$ \\forall x \\in \\mathbb{R}, \\; g'(X)  =\\frac{e^{X}+1}{e^{X}} \\frac{e^{X} ({e^{X}+1}) - e^{X}e^{X}}{{e^{X}+1}^{2}}  = \\frac{1}{e^X+1}$$\n",
    "$$ \\forall x \\in \\mathbb{R}, \\; g''(X) = -\\frac{e^X}{{(e^X+1)}^2} < 0$$\n",
    "\n",
    "Conclusion :  g is concave\n",
    "\n",
    "\n",
    "- Then, let's pose i  a real function following:\n",
    "$$ \\forall x \\in \\mathbb{R}, \\; i(x) = log(1-\\phi(x)) = log(\\frac{1}{e^X +1}) $$\n",
    "\n",
    "We can calculate the second derivative of i:\n",
    "$$ \\forall x \\in \\mathbb{R}, \\; i'(X) = -\\frac{e^{X}}{e^{X}+1} = -\\frac{1}{e^{-X}+1}$$\n",
    "$$ \\forall x \\in \\mathbb{R}, \\; i''(X) = -\\frac{e^{-X}}{(e^{-X}+1)^2} < 0$$\n",
    "\n",
    "Conclusion :  i is concave\n",
    "\n",
    "\n",
    "- Then, let's pose h a real function following:\n",
    "\n",
    "$$ \\forall x \\in \\mathbb{R}^2, \\; h(x_1,x_2) = log(\\phi(x_1) - \\phi(x_2)) $$\n",
    "\n",
    "For this part, we've tried to use the results from these article :  [(1)](http://fa.bianp.net/uploads/2014/consistency-or.pdf), [(2)](http://fa.bianp.net/uploads/2014/consistency-or.pdf), [(3)](http://www3.stat.sinica.edu.tw/ss_newpaper/SS-2017-0465_na.pdf) and [(4)](http://fa.bianp.net/blog/2013/logistic-ordinal-regression/) \n",
    "\n",
    "\n",
    "$$\\nabla_\\beta h = \\frac{y_{ij}\\Big[\\nabla_B\\phi(\\alpha_j + \\beta^T x_i) - \\nabla_B\\phi(\\alpha_{j-1} + \\beta^T x_i)\\Big]}{\\phi(\\alpha_j + \\beta^T x_i) - \\phi(\\alpha_{j-1} + \\beta^T x_i)}$$\n",
    "\n",
    "Deriving once more, we're using that :\n",
    "$$ (\\frac{u}{v})' \\implies \\frac{u'}{v} -  \\frac{uv'}{v^2}  $$\n",
    "\n",
    "Hence :\n",
    "\n",
    "\n",
    "$$\\nabla_\\beta^2 h = y_{ij}x_i^T x_i \\Big[ \\frac{\\phi''(\\alpha_j + \\beta^T x_i) - \\phi''(\\alpha_{j-1} + \\beta^T x_i)}{\\phi(\\alpha_j + \\beta^T x_i) - \\phi(\\alpha_{j-1} + \\beta^T x_i)} - \\Big[\\frac{\\phi'(\\alpha_j + \\beta^T x_i) - \\phi'(\\alpha_{j-1} + \\beta^T x_i)}{\\text{v}} \\Big]^2\\Big] $$\n",
    "\n",
    "And : \n",
    "\n",
    "$$\\frac{\\partial^2 h}{\\partial \\alpha_j^2} = y_{ij} \\Big[ \\frac{\\phi''(\\alpha_j + \\beta^T x_i) - \\phi''(\\alpha_{j-1} + \\beta^T x_i)}{\\phi(\\alpha_j + \\beta^T x_i) - \\phi(\\alpha_{j-1} + \\beta^T x_i)} - \\Big[\\frac{\\phi'(\\alpha_j + \\beta^T x_i) - \\phi'(\\alpha_{j-1} + \\beta^T x_i)}{\\text{v}} \\Big]^2\\Big] $$\n",
    "\n",
    "With \n",
    "$$\n",
    "\\phi(x) = \\frac{1}{1 + e^{-x}}\\\\\n",
    "\\phi'(x) = \\frac{e^{-x}}{(1 + e^{-x})^2}\\\\\n",
    "$$\n",
    "\n",
    "We have that :\n",
    "\n",
    "$$\\begin{cases}\n",
    "    \\phi\\text{ is monotonous increasing}\\\\\n",
    "    \\alpha_1 \\leq \\dots \\leq \\alpha_{k-1} \\text{ by definition in a convexe space on }\\mathbb{R} \\\\\n",
    "     x_i^T x_i \\text{ is semi-definite positive}\\\\\n",
    "\\end{cases}$$\n",
    " \n",
    "Conclusion :  h is concave\n",
    "\n",
    "Then, f being equal to the opposite of the sum of the funtion previously proved concave. Therefore it is a convex function. \n",
    "\n",
    "Conclusion :  $\\mathcal{P}_\\alpha$ is a convexe problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "Generate data under the above model and then estimate $\\alpha$ and $\\beta$ using maximum likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 1000  # number of samples\n",
    "p = 2  # number of features\n",
    "k = 3  # number of classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate parameters and compute probability distributions for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10.67517827   9.85548133]\n",
      "[-0.79241992 -0.30796153]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "X = 15 * rng.normal(size=(n, p))\n",
    "alpha = np.sort(np.linspace(-10, 10, k - 1) + rng.randn(k - 1))\n",
    "beta = rng.randn(p)\n",
    "print(alpha)\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute the quantity $P(Y = j \\mid x_i)$ for $j= 1, \\dots , k$, and $i= 1, \\dots, n$.\n",
    "\n",
    "First, let us compute an array containing the values $P(Y < j \\mid x_i)$ for $j= 1, \\dots , k+1$ and $i=1, \\dots, n$. (we denote this array `F`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 1.19425874e-07, 9.89950079e-01, 1.00000000e+00],\n",
       "       [0.00000000e+00, 9.22303606e-12, 7.54978894e-03, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.10105626e-03, 9.99998900e-01, 1.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 2.52740373e-09, 6.75810908e-01, 1.00000000e+00],\n",
       "       [0.00000000e+00, 1.85838624e-03, 9.99999349e-01, 1.00000000e+00],\n",
       "       [0.00000000e+00, 4.98712917e-03, 9.99999758e-01, 1.00000000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def phi(t):\n",
    "    return 1. / (1. + np.exp(-t))\n",
    "\n",
    "F = phi(np.dot(X, beta)[:, np.newaxis] + alpha)\n",
    "F = np.concatenate([np.zeros((n , 1)), F, np.ones((n , 1))], axis=1)\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.19425874e-07, 9.89949960e-01, 1.00499208e-02],\n",
       "       [9.22303606e-12, 7.54978894e-03, 9.92450211e-01],\n",
       "       [1.10105626e-03, 9.98897844e-01, 1.09991567e-06],\n",
       "       ...,\n",
       "       [2.52740373e-09, 6.75810905e-01, 3.24189092e-01],\n",
       "       [1.85838624e-03, 9.98140963e-01, 6.51184001e-07],\n",
       "       [4.98712917e-03, 9.95012629e-01, 2.41894393e-07]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute P(Y = j | x)\n",
    "proba = np.diff(F, axis=1)\n",
    "assert proba.shape == (n, k)\n",
    "proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of all probas for each sample should be 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_allclose(np.sum(proba, axis=1), np.ones(n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate $Y$ according to $P(Y = j \\mid x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 2, 1, 1, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([rng.choice(np.arange(k), size=1, p=pi)[0] for pi in proba])\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for j in range(k):\n",
    "    Xj = X[y == j]\n",
    "    plt.plot(Xj[:, 0], Xj[:, 1], 'o', label='y = %d' % j, alpha=0.5)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log-Likelihood function\n",
    "\n",
    "We adopt the parametrization from $(\\mathcal{P}_\\alpha)$. The vector of parameters `params` has `k-1 + p` entries. The first `k-1` are the alphas $\\alpha$ and the last `p` entries correspond to $\\beta$. The function that predicts the probabilities of each sample reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_alphas(params, X=X):\n",
    "    \"\"\"Compute the probability of each sample in X.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    params: array, shape (k - 1 + p,)\n",
    "        Parameters of the model. The first k - 1 entries are the alpha_j,\n",
    "        the remaining p ones are the entries of beta.\n",
    "        \n",
    "    X: array, shape (n, p)\n",
    "        Design matrix.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    proba : ndarray, shape (n, k)\n",
    "        The proba of belonging to each class for each sample.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_thresh = params.size - n_features\n",
    "    alpha = params[:n_thresh]\n",
    "    beta = params[n_thresh:]\n",
    "    F = phi(np.dot(X, beta)[:, np.newaxis] + alpha)\n",
    "    F = np.concatenate(\n",
    "        [np.zeros((n_samples , 1)), F, np.ones((n_samples , 1))], axis=1)\n",
    "    proba = np.diff(F, axis=1)\n",
    "    return proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding of `y` can be done with scikit-learn `LabelBinarizer`. As it's a matrix, we call it `Y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def binarize(y):\n",
    "    le = preprocessing.LabelBinarizer()\n",
    "    Y = le.fit_transform(y)\n",
    "    if Y.shape[1] == 1:\n",
    "        Y = np.concatenate([1 - Y, Y], axis=1)\n",
    "    return Y\n",
    "\n",
    "Y = binarize(y)\n",
    "Y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The negative log-likelihood then reads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.86949983576653"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def negloglik_alphas(params, X=X, Y=Y):\n",
    "    proba = predict_proba_alphas(params, X)\n",
    "    assert Y.shape == proba.shape\n",
    "    return -np.sum(np.log(np.sum(proba * Y, axis=1) + np.finfo('float').eps))\n",
    "\n",
    "params = np.concatenate([alpha, beta])\n",
    "negloglik_alphas(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 2:</b>\n",
    "     <ul>\n",
    "      <li>Justify why applying coordinate descent or proximal gradient descent to $(\\mathcal{P}_\\alpha)$ is not easy (or even possible?).</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By definition \"$\\alpha = \\{ \\alpha_j \\}_{j=1}^{k-1}$ is an increasing sequence of constants\" sampled as follows :\n",
    "\"alpha = np.sort(np.linspace(-10, 10, k - 1) + rng.randn(k - 1))\"\n",
    "\n",
    "Obviously, each corrdinate $\\alpha_j$ is  correlated to the other ones considering $\\alpha_j = \\alpha_{j-1} + d_j$. \n",
    "\n",
    "- Let's study a pessimistic example of highly correlated inputs to understand why these methods do no work well :\n",
    "\n",
    "Assuming we have perfect correlation between two features, $$x1=x2$$\n",
    "and you want a linear function that maps X to Y, $$Y=f(X)$$ where $$f(X)=0+1x1+2x2$$\n",
    "\n",
    "\n",
    "Both following solution provide \"correct\" answer :\n",
    "\n",
    "$$(1=0 2=1), (1=1,2=0)$$ \n",
    "\n",
    "\n",
    "Actually all solution as follow will give the same answer :\n",
    "\n",
    "$$\\forall \\beta_1,\\beta_2  \\in \\mathbb{{R}^d},  1+2=1$$\n",
    "\n",
    "- We shed light on the phenomenon during Lab2 : all Gradient Descent methods perform better while the direction of the gradient at each iteration points to the optimal point. Therefore we can minimize each i separately and get to a good answer : that's the core assumption of both of these methods, differentiating the function only one coordinate at a time. \n",
    "\n",
    "Example : an iteration of SGD writes\n",
    "\n",
    "- Pick $i$ uniformly at random in $\\{1, \\ldots, n\\}$\n",
    "- Apply\n",
    "$$\n",
    "x_{t+1} \\gets x_t - \\frac{\\eta_0}{\\sqrt{t+1}} \\nabla f_i(x_t)\n",
    "$$\n",
    "\n",
    "Deep down, we have to remember that increasing correlation implies a lower condition number explaining the slower convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparametrization\n",
    "\n",
    "To fix the problem, we propose to reparametrize the problem with a new vector $\\eta \\in \\mathbb{R}^{k-1}$ such that $\\alpha_j = \\sum_{l=1}^{j} \\eta_l$ with $\\eta_j \\geq 0$ for $j \\geq 2$.\n",
    "\n",
    "We denote by $\\mathcal{L}(\\eta, \\beta)$ the corresponding negative log-likelihood:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\eta, \\beta) =\n",
    "- \\sum_{i=1}^{n} \\left [ y_{i1} \\log \\left ( \\phi(\\eta_1 + \\beta^T x_i) \\right )\n",
    "+ \\sum_{j=2}^{k-1} y_{ij} \\log \\left ( \\phi(\\sum_{l=1}^j \\eta_l + \\beta^T x_i) - \\phi(\\sum_{l=1}^{j-1} \\eta_l + \\beta^T x_i) \\right ) + y_{ik} \\log \\left ( 1 - \\phi(\\sum_{l=1}^{k-1} \\eta_l + \\beta^T x_i) \\right ) \\right ] .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 3:</b>\n",
    "     <ul>\n",
    "      <li>Show that $(\\mathcal{P}_\\alpha)$ can be rewritten as an unconstrained convex problem $(\\mathcal{P}_\\eta)$.\n",
    "$$\n",
    "    (\\mathcal{P}_\\eta): \\left\\{\n",
    "\t\\begin{aligned}\n",
    "\t\\min_{\\eta \\in \\mathbb{R}^{k-1}, \\beta \\in \\mathbb{R}^{p}} \\quad \\mathcal{L}(\\eta, \\beta) + \\lambda \\mathcal{R}(\\beta) + \\sum_{j=2}^{k-1} g_j(\\eta_j)\\\\\n",
    "\t\\end{aligned}\n",
    "    \\right.\n",
    "$$\n",
    "          You will detail what are the functions $g_j$.\n",
    "    </li>\n",
    "    <li>\n",
    "        Justify that the problem can be solved with Proximal Gradient Descent, Proximal Coordinate Descent and the L-BFGS-B algorithm (implemented in scipy.optimize).\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By using $\\alpha_j = \\sum_{l=1}^{j} \\eta_l$ with $\\eta_j \\geq 0$ for $j \\geq 2$, we insure that: $\\alpha_1 \\leq \\dots \\leq \\alpha_{k-1} $\n",
    "\n",
    "So we can replace the constraints of $(\\mathcal{P}_\\alpha)$ by new constraints imposing that:$\\eta_j \\geq 0$ for $j \\geq 2$ \n",
    "\n",
    "We can use the indicator function $\\iota$ to add this constraint to the function to minimize by defining:\n",
    "$\\boxed{g_j(\\eta_j)=\\iota_{\\mathbb{R}^+}(\\eta_j)}$\n",
    "\n",
    "- This problem can be solved by Proximal Gradient Descent, Proximal Coordinate Descent and by the L-BFGS-B algorithm because:  $\\mathcal{L}(\\eta,\\beta)$ is a convexe and differentiable function, and $\\lambda \\mathcal{R}(\\beta) + \\sum_{j=2}^{k-1} g_j(\\eta_j)$ is a convexe function. Furthermore, each variable is now independant to the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\forall j,  1 \\leq j \\leq k-1: \\eta_j   \\in \\mathbb{{R}^{+*}}$$\n",
    "\n",
    "With  $\\alpha_j = \\sum_{i=1}^{j} \\eta_i$ , we have the previous constraint holding: \n",
    "$$\\alpha_1 \\leq \\dots \\leq \\alpha_{k-1} $$\n",
    "\n",
    "So we can replace the constraints of $(\\mathcal{P}_\\alpha)$ by new constraints imposing that:$\\eta_j \\geq 0$ for $j \\geq 2$ \n",
    "\n",
    "We can use the indicator function $\\iota$ to add this constraint to the function to minimize by defining:\n",
    "$\\boxed{g_j(\\eta_j)=\\iota_{\\mathbb{R}^+}(\\eta_j)}$\n",
    "\n",
    "- This problem can be solved by Proximal Gradient Descent, Proximal Coordinate Descent and by the L-BFGS-B algorithm because:  $\\mathcal{L}(\\eta,\\beta)$ is a convexe and differentiable function, and $\\lambda \\mathcal{R}(\\beta) + \\sum_{j=2}^{k-1} g_j(\\eta_j)$ is a convexe function. Furthermore, each variable is now independant to the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 4:</b>\n",
    "     <ul>\n",
    "      <li>Introducing the functions $f_2(\\eta, \\beta) = \\tfrac{\\lambda}{2}\\|\\beta\\|_2^2 + \\sum_{j=2}^{k-1} g_j(\\eta_j)$ (corresponding to the case where $\\mathcal{R}=\\tfrac{1}{2}\\|\\beta\\|_2^2$) and $f_1(\\eta, \\beta) = \\lambda \\|\\beta\\|_1 + \\sum_{j=2}^{k-1} g_j(\\eta_j)$ (corresponding to the case where $\\mathcal{R}=\\|\\beta\\|_1$), compute and implement the proximal operators of $f_1$ and $f_2$.\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "In the code below, `lambda` being a reserved keyword in Python, we denote $\\lambda$ by `reg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $prox_{f1} (\\phi_{\\eta_1}, ... \\phi_{\\eta_{k-1}}, \\phi_\\beta) = ( \\phi_{\\eta_1},proj_{R^+}(\\phi_{\\eta_2}), ... proj_{R^+}(\\phi_{\\eta_{k-1}}),SoftThreshold_\\lambda(\\phi_\\beta)) $\n",
    "- $prox_{f2} (\\phi_{\\eta_1}, ... \\phi_{\\eta_{k-1}}, phi_\\beta) = (\\phi_{\\eta_1},proj_{R^+}(\\phi_{\\eta_2}), ... proj_{R^+}(\\phi_{\\eta_{k-1}}), \\frac{\\phi_\\beta}{\\lambda + 1}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def prox_f2(params, reg=1., n_classes=k):\n",
    "    # TODO\n",
    "    prox = params.copy()\n",
    "    \n",
    "    for i in range(1, k-1):\n",
    "        if prox[i] < 0:\n",
    "            prox[i] = 0 \n",
    "    \n",
    "    prox[k-1:] = params[k-1:] / (reg + 1)       \n",
    "    # END TODO\n",
    "    return prox\n",
    "\n",
    "\n",
    "def prox_f1(params, reg=1., n_classes=k):\n",
    "    # TODO  \n",
    "    n=params.size\n",
    "    prox = params.copy()\n",
    "    \n",
    "    for i in range(1, k-1):\n",
    "        if prox[i] < 0:\n",
    "            prox[i] = 0 \n",
    "            \n",
    "    for i in range(k-1, n):\n",
    "        if prox[i] < -reg:\n",
    "            prox[i] = prox[i] + reg\n",
    "        elif prox[i] > reg:\n",
    "            prox[i] = prox[i] - reg\n",
    "        else:\n",
    "            prox[i] = 0\n",
    "    # END TODO\n",
    "    return prox\n",
    "\n",
    "rng = np.random.RandomState(5)\n",
    "x = rng.randn(p + k - 1)\n",
    "l_l1 = 1.\n",
    "l_l2 = 2.\n",
    "ylim = [-1, 3]\n",
    "\n",
    "plt.figure(figsize=(15.0, 4.0))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.stem(x)\n",
    "plt.title(\"Original parameter\", fontsize=16)\n",
    "plt.ylim(ylim)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.stem(prox_f1(x, l_l1))\n",
    "plt.title(\"Proximal Lasso\", fontsize=16)\n",
    "plt.ylim(ylim)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.stem(prox_f2(x, l_l2))\n",
    "plt.title(\"Proximal Ridge\", fontsize=16)\n",
    "plt.ylim(ylim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implementation of the solvers\n",
    "\n",
    "### L-BFGS-B Solver\n",
    "\n",
    "We will start by using the L-BFGS solver provided by `scipy`, without specifying the gradient function. In this case, the [`fmin_l_bfgs_b`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin_l_bfgs_b.html) function will approximate the gradient using a finite difference method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 5:</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Implement the new predict_proba function using the new parametrization with $\\eta$\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(params, X=X):\n",
    "    \"\"\"Compute the probability of every sample in X.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : ndarray, shape (k - 1 + p,)\n",
    "        The parameters. The first k-1 values are the etas\n",
    "        and the last p ones are beta.\n",
    "        \n",
    "    X: array, shape (n, p)\n",
    "        Design matrix.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    proba : ndarray, shape (n, k)\n",
    "        The proba of belonging to each class for each sample.\n",
    "    \"\"\"\n",
    "    n_samples, n_features = X.shape\n",
    "    n_thresh = params.size - n_features\n",
    "    eta = params[:n_thresh]\n",
    "    beta = params[n_thresh:]\n",
    "    alpha = eta.cumsum()\n",
    "    # TODO\n",
    "    F = phi(np.dot(X, beta)[:, np.newaxis] + alpha)\n",
    "    F = np.concatenate(\n",
    "        [np.zeros((n_samples , 1)), F, np.ones((n_samples , 1))], axis=1)\n",
    "    proba = np.diff(F, axis=1)\n",
    "    # END TODO\n",
    "    return proba\n",
    "\n",
    "\n",
    "def negloglik(params, X=X, Y=Y):\n",
    "    \"\"\"Compute the negative log-likelihood.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    params : ndarray, shape (p + k - 1,)\n",
    "        The parameters. The first k-1 values are the etas\n",
    "        and the remaining ones are the entries of beta.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    nlk : float\n",
    "        The negative log-likelihood to be minimized.\n",
    "    \"\"\"\n",
    "    proba = predict_proba(params, X=X)\n",
    "    assert Y.shape == proba.shape\n",
    "    return -np.sum(np.log(np.sum(proba * Y, axis=1) + np.finfo('float').eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell is to check your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check your implementation\n",
    "def alpha_to_eta(alpha):\n",
    "    eta = alpha.copy()\n",
    "    eta[1:] = np.diff(alpha)\n",
    "    return eta\n",
    "\n",
    "# Compute with P_alpha parametrization:\n",
    "negloglik_alphas(np.concatenate([alpha, beta]))\n",
    "\n",
    "# Compute with P_eta parametrization:\n",
    "eta = alpha_to_eta(alpha)\n",
    "params = np.concatenate([eta, beta])\n",
    "\n",
    "# Check that log-likelihoods match\n",
    "assert abs(negloglik(params) - negloglik_alphas(np.concatenate([alpha, beta]))) < 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 6:</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Solve the optimization using the `fmin_l_bfgs_b` function.\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "HINT: You can specify positivity contraints for certain variables using the `bounds` parameter of `fmin_l_bfgs_b`. Infinity for numpy is `np.inf`.\n",
    "\n",
    "The estimate of $\\beta$ (resp. $\\eta$ and $\\alpha$) should be called `beta_hat` (resp. `eta_hat` and `alpha_hat`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def sigmoid(x):  \n",
    "    return np.exp(-np.logaddexp(0, -x))\n",
    "\n",
    "sigmoid = np.vectorize(sigmoid)\n",
    "\n",
    "\n",
    "def negloglik(params, X=X, Y=Y):\n",
    "    \n",
    "    n_samples, n_features = X.shape\n",
    "    n_thresh = params.size - n_features\n",
    "    eta = params[:n_thresh]\n",
    "    beta = params[n_thresh:]\n",
    "    alpha = eta.cumsum()\n",
    "\n",
    "    L = np.nan_to_num(csr_matrix(Y[:,0]).multiply(np.log(sigmoid(eta[0] + X.dot(beta)))))\n",
    "    \n",
    "    for j in range(1, n_thresh):\n",
    "        L += np.nan_to_num(csr_matrix(Y[:,j]).multiply(np.log(sigmoid(alpha[j] + X.dot(beta)) \n",
    "                                                              - sigmoid(alpha[j-1] + X.dot(beta)))))\n",
    "        \n",
    "    L += np.nan_to_num(csr_matrix(Y[:,n_thresh]).multiply(np.log(1. - sigmoid(alpha[n_thresh-1] + X.dot(beta)))))\n",
    "    return -np.sum(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\piega\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1000 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negloglik(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-570a4fa6e888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbounds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mparams_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegloglik\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapprox_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0meta_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_hat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[1;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[1;32m--> 199\u001b[1;33m                            **opts)\n\u001b[0m\u001b[0;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[0;32m    201\u001b[0m          \u001b[1;34m'task'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'message'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_approx_fprime_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py\u001b[0m in \u001b[0;36m_approx_fprime_helper\u001b[1;34m(xk, f, epsilon, args, f0)\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mei\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m         \u001b[0mgrad\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m         \u001b[0mei\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "x0 = np.zeros(p + k - 1)\n",
    "x0[:k - 1] = np.arange(k - 1) \n",
    "bounds = [(None, None)] + [(0, np.inf) for j in range(k-2)] + [(None, None)] * p\n",
    "\n",
    "params_hat, _, _ = fmin_l_bfgs_b(negloglik, approx_grad=True, x0=x0, bounds=bounds)\n",
    "\n",
    "eta_hat = params_hat[:k-1]\n",
    "beta_hat = params_hat[k-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_proba = predict_proba(np.concatenate([eta_hat, beta_hat]))\n",
    "y_pred = np.argmax(Y_proba, axis=1)\n",
    "\n",
    "for j in range(k):\n",
    "    Xj = X[y_pred == j]\n",
    "    plt.plot(Xj[:, 0], Xj[:, 1], 'o', label='y = %d' % j, alpha=0.5)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the gradients\n",
    "\n",
    "We have so far been lazy by asking `fmin_l_bfgs_b` to approximate the gradient.\n",
    "You are going to fix this using either one of the next 2 options:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 7 (option 1):</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Implement the function grad_negloglik that computes the gradient of negloglik.\n",
    "    </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 7 (option 2):</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Implement the function grad_negloglik that computes the gradient of negloglik\n",
    "        using the <a href=\"https://github.com/HIPS/autograd\">autograd</a> package.\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "**HINT** : QUESTION 7 (option 1) you can use the fact that: $\\log(\\phi(t))' = 1 - \\phi(t)$ and $\\phi(t)' = \\phi(t) (1 - \\phi(t))$\n",
    "\n",
    "You can check your implementation of the function `grad_negloglik` with the check_grad function. However **WARNING** your code is likely to be numerically quite unstable due to the numerous `log` and `exp` with tiny values that are probabilities. You may want to work with log of probabilities but **warning** this is not easy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1\n",
    "from scipy.misc import logsumexp\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def grad_negloglik(params, X=X, Y=Y):\n",
    "    # TODO\n",
    "    eta = params[:k-1]\n",
    "    beta = params[k-1:]\n",
    "    alpha = eta.cumsum()\n",
    "    \n",
    "    grad= []\n",
    "    \n",
    "    #grad en eta1\n",
    "    grad_eta1 = csr_matrix(Y[:,0]).multiply(1. - sigmoid(eta[0] + X.dot(beta)))\n",
    "    for j in range(1,k-1):\n",
    "        grad_eta1 += csr_matrix(Y[:,j]).multiply((sigmoid(sum_1toJ(eta, j) + X.dot(beta)) * (1 - sigmoid(sum_1toJ(eta,j) + X.dot(beta))) -\n",
    "                                         sigmoid(sum_1toJ(eta, j-1) + X.dot(beta)) * (1 - sigmoid(sum_1toJ(eta,j) + X.dot(beta))))/ \n",
    "                                         (sigmoid(sum_1toJ(eta, j) + X.dot(beta)) - sigmoid(sum_1toJ(eta,j-1) + X.dot(beta)))) \n",
    "    grad_eta1 += csr_matrix(Y[:,k-1]).multiply(-sigmoid(sum_1toJ(eta,k-2) + X.dot(beta)))\n",
    "    grad.append(np.sum(grad_eta1))\n",
    "    \n",
    "    #grad en eta2\n",
    "    grad_eta2 = np.zeros(grad_eta1.shape)\n",
    "    for j in range(1,k-1):\n",
    "        grad_eta2 += csr_matrix(Y[:,j]).multiply(sigmoid(sum_1toJ(eta, j) + X.dot(beta)) * (1 - sigmoid(sum_1toJ(eta,j) + X.dot(beta))) / \n",
    "                                         (sigmoid(sum_1toJ(eta, j) + X.dot(beta)) - sigmoid(sum_1toJ(eta,j-1) + X.dot(beta))))\n",
    "    grad_eta2 += csr_matrix(Y[:,k-1]).multiply( -sigmoid(sum_1toJ(eta,k-2) + X.dot(beta)))\n",
    "    grad.append(np.sum(grad_eta2))\n",
    "    \n",
    "    #grad en beta\n",
    "    grad_beta = grad_eta1.dot(X)\n",
    "    grad.append(grad_beta[0][0])\n",
    "    grad.append(grad_beta[0][1])\n",
    "    \n",
    "    # END TODO\n",
    "    return grad\n",
    "\n",
    "grad_negloglik(params, X=X, Y=Y)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2\n",
    "\n",
    "import autograd.numpy as np\n",
    "from autograd import grad\n",
    "\n",
    "def sigmoid(x):  \n",
    "    return np.exp(-np.logaddexp(0, -x))\n",
    "\n",
    "def negloglik_autograd(params, X=X, Y=Y):\n",
    "    \"\"\"Compute the negative log-likelihood\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    params : ndarray, shape (p + k - 1,)\n",
    "        The parameters. The first k-1 values are the etas\n",
    "        and the remaining p ones correspond to beta.\n",
    "    X : ndarray, shape (n, p)\n",
    "        Design matrix.\n",
    "    Y : ndarray, shape (n, k)\n",
    "        The target after one-hot encoding.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nlk : float\n",
    "        The negative log-likelihood to be minimized.\n",
    "    \"\"\"\n",
    "    # TODO\n",
    "    n_samples, n_features = X.shape\n",
    "    n_thresh = params.size - n_features\n",
    "    eta = params[:n_thresh]\n",
    "    beta = params[n_thresh:]\n",
    "    alpha = eta.cumsum()\n",
    "    \n",
    "    L = 0\n",
    "    for i in range(Y.shape[0]):\n",
    "        if Y[i, 0] != 0:\n",
    "            L += np.nan_to_num(Y[i,0] * np.log(sigmoid(eta[0] + np.dot(X[i],beta))))\n",
    "            \n",
    "        for j in range(1, n_thresh):\n",
    "    \n",
    "            if Y[i,j] != 0:\n",
    "                L += np.nan_to_num(Y[i,j] * np.log(sigmoid(alpha[j] + np.dot(X[i], beta)) \n",
    "                                                   - sigmoid(alpha[j-1] + np.dot(X[i], beta))))\n",
    "        if Y[i, n_thresh] != 0:\n",
    "            L += np.nan_to_num(Y[i,n_thresh] * (np.log(1. - sigmoid(alpha[n_thresh-1] + np.dot(X[i], beta)))))\n",
    "    \n",
    "\n",
    "    return - L\n",
    "    # END TODO\n",
    "\n",
    "grad_negloglik_auto = grad(negloglik_autograd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import check_grad\n",
    "rng = np.random.RandomState(42)\n",
    "x0 = rng.randn(p + k - 1)\n",
    "x0[1:k - 1] = np.abs(x0[1:k - 1])\n",
    "# WARNING: check_grad is likely to return a quite high value\n",
    "# due to numerical instability with exp and log with tiny\n",
    "# probability values. Don't be surprised as long as your\n",
    "# solvers below converge.\n",
    "check_grad(negloglik, grad_negloglik_auto, x0=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plug your gradient into L-BFGS and check the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.zeros(p + k - 1)\n",
    "x0[:k - 1] = np.arange(k - 1)  # initiatlizing with etas all equal to zero is a bad idea!\n",
    "bounds = [(None, None)] + [(0, np.inf) for j in range(k-2)] + [(None, None)] * p\n",
    "x_hat, _, _ = fmin_l_bfgs_b(negloglik, fprime=grad_negloglik_auto,\n",
    "                            x0=x0, bounds=bounds)\n",
    "Y_proba = predict_proba(x_hat)\n",
    "y_pred = np.argmax(Y_proba, axis=1)\n",
    "\n",
    "for j in range(k):\n",
    "    Xj = X[y_pred == j]\n",
    "    plt.plot(Xj[:, 0], Xj[:, 1], 'o', label='y = %d' % j, alpha=0.5)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 9:</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Wrap this into a function of X, y and lbda that implements\n",
    "        the function proportional_odds_lbfgs_l2 that will be\n",
    "        used to get a good value of x_min (minimum of the L2 regularized\n",
    "        model).\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you we give you the code of the objective to minimize\n",
    "in case you use $\\ell_1$ or $\\ell_2$ penalty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pobj_l1(params, X=X, Y=Y, lbda=1.):\n",
    "    n_features = X.shape[1]\n",
    "    beta = params[-n_features:]\n",
    "    n_thresh = Y.shape[1] - 1\n",
    "    eta = params[:n_thresh]\n",
    "    if np.any(eta[1:] < 0):\n",
    "        return np.inf\n",
    "    return negloglik(params, X=X, Y=Y) + lbda * np.sum(np.abs(beta))\n",
    "\n",
    "\n",
    "def pobj_l2(params, X=X, Y=Y, lbda=1.):\n",
    "    n_features = X.shape[1]\n",
    "    beta = params[-n_features:]\n",
    "    n_thresh = Y.shape[1] - 1\n",
    "    eta = params[:n_thresh]\n",
    "    if np.any(eta[1:] < 0):\n",
    "        return np.inf\n",
    "    return negloglik(params, X=X, Y=Y) + lbda / 0.5 * np.dot(beta, beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportional_odds_lbfgs_l2(X, y, lbda):\n",
    "    Y = binarize(y)\n",
    "    n_samples, n_features = X.shape\n",
    "    n_classes = Y.shape[1]\n",
    "\n",
    "    # TODO\n",
    "    x_init = np.zeros(n_features + n_classes - 1)\n",
    "    x_init[:n_classes - 1] = np.arange(n_classes - 1)\n",
    "    bounds = [(None, None)] + [(0, np.inf) for j in range(n_classes-2)] + [(None, None)] * n_features\n",
    "    x_min, _, _ = fmin_l_bfgs_b(pobj_l2,\n",
    "                                args= (X,Y),\n",
    "                                fprime = grad_negloglik_auto,\n",
    "                                x0=x_init,\n",
    "                                bounds=bounds)\n",
    "    # END TODO\n",
    "    return x_min\n",
    "\n",
    "x_min = proportional_odds_lbfgs_l2(X, y, lbda=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that `x_min` is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_proba = predict_proba(x_min)\n",
    "y_pred = np.argmax(Y_proba, axis=1)\n",
    "\n",
    "for j in range(k):\n",
    "    Xj = X[y_pred == j]\n",
    "    plt.plot(Xj[:, 0], Xj[:, 1], 'o', label='y = %d' % j, alpha=0.5)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a gradient of the negative loglikelihood term we can implement other solvers. Namely you are going to implement:\n",
    "\n",
    "- Proximal Gradient Descent (PGD aka ISTA)\n",
    "- Accelerated Proximal Gradient Descent (APGD aka FISTA)\n",
    "\n",
    "Before this we are going to define the `monitor` class previously used in the second lab as well as plotting functions useful to monitor convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class monitor(object):\n",
    "    def __init__(self, algo, obj, x_min, args=()):\n",
    "        self.x_min = x_min\n",
    "        self.algo = algo\n",
    "        self.obj = obj\n",
    "        self.args = args\n",
    "        if self.x_min is not None:\n",
    "            self.f_min = obj(x_min, *args)\n",
    "\n",
    "    def run(self, *algo_args, **algo_kwargs):\n",
    "        t0 = time.time()\n",
    "        _, x_list = self.algo(*algo_args, **algo_kwargs)\n",
    "        self.total_time = time.time() - t0\n",
    "        self.x_list = x_list\n",
    "        if self.x_min is not None:\n",
    "            self.err = [linalg.norm(x - self.x_min) for x in x_list]\n",
    "            self.obj = [self.obj(x, *self.args) - self.f_min for x in x_list]\n",
    "        else:\n",
    "            self.obj = [self.obj(x, *self.args) for x in x_list]\n",
    "\n",
    "\n",
    "def plot_epochs(monitors, solvers):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    for monit in monitors:\n",
    "        ax1.semilogy(monit.obj, lw=2)\n",
    "        ax1.set_title(\"Objective\")\n",
    "        ax1.set_xlabel(\"Epoch\")\n",
    "        ax1.set_ylabel(\"objective\")\n",
    "\n",
    "    ax1.legend(solvers)\n",
    "\n",
    "    for monit in monitors:\n",
    "        if monit.x_min is not None:\n",
    "            ax2.semilogy(monit.err, lw=2)\n",
    "            ax2.set_title(\"Distance to optimum\")\n",
    "            ax2.set_xlabel(\"Epoch\")\n",
    "            ax2.set_ylabel(\"$\\|x_k - x^*\\|_2$\")\n",
    "\n",
    "    ax2.legend(solvers)\n",
    "\n",
    "\n",
    "def plot_time(monitors, solvers):\n",
    "    for monit in monitors:\n",
    "        objs = monit.obj\n",
    "        plt.semilogy(np.linspace(0, monit.total_time, len(objs)), objs, lw=2)\n",
    "        plt.title(\"Loss\")\n",
    "        plt.xlabel(\"Timing\")\n",
    "        plt.ylabel(\"$f(x_k) - f(x^*)$\")\n",
    "\n",
    "    plt.legend(solvers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 8a:</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Implement the proximal gradient descent (PGD) method\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "The parameter `step` is the size of the gradient step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(x_init, grad, prox, n_iter=100, step=1., store_every=1,\n",
    "        grad_args=(), prox_args=()):\n",
    "    \"\"\"Proximal gradient descent algorithm.\"\"\"\n",
    "    x = x_init.copy()\n",
    "    x_list = []\n",
    "    for i in range(n_iter):\n",
    "        ### TODO\n",
    "        x = prox(x - step * grad(x, *grad_args), *prox_args)\n",
    "        ### END TODO\n",
    "        if i % store_every == 0:\n",
    "            x_list.append(x.copy())\n",
    "    return x, x_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 8b:</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Using the monitor class and the plot_epochs function, display the convergence.\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "NOTE: You will have to provide a `step` value, which should be theoretially less than `1 / lipschitz_constant`. You will propose a value for it but you are not expected to provide a mathematical proof, unless you think it's a moral duty to give one..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you we give you the proximal operator functions for $\\ell_1$ and $\\ell_2$ regularized models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prox_l1(params, step, lbda, n_classes):\n",
    "    return prox_f1(params, reg=step * lbda, n_classes=n_classes)\n",
    "\n",
    "def prox_l2(params, step, lbda, n_classes):\n",
    "    return prox_f2(params, reg=step * lbda, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = np.zeros(p + k - 1)\n",
    "x_init[:k - 1] = np.arange(k - 1)\n",
    "n_iter = 1000\n",
    "lbda = .1\n",
    "step = 0.0001\n",
    "\n",
    "# TODO\n",
    "monitor_pgd_l2 = monitor(pgd, pobj_l2, x_min, (X, Y, lbda))\n",
    "monitor_pgd_l2.run(x_init, grad_negloglik_auto, prox_l2, n_iter, step,\n",
    "                  grad_args=(X, Y), prox_args=(step,lbda, k))\n",
    "# END TODO\n",
    "\n",
    "monitors = [monitor_pgd_l2]\n",
    "solvers = [\"PGD\"]\n",
    "plot_epochs(monitors, solvers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the $\\ell_1$ regularization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = np.zeros(p + k - 1)\n",
    "x_init[:k - 1] = np.arange(k - 1)\n",
    "\n",
    "n_iter = 1000\n",
    "lbda = .1\n",
    "step = 0.0001\n",
    "\n",
    "# Run PGD for L1\n",
    "monitor_pgd_l1 = monitor(pgd, pobj_l1, x_min=x_init, args=(X, Y, lbda))\n",
    "monitor_pgd_l1.run(x_init, grad_negloglik_auto, prox_l1, n_iter, step,\n",
    "                   grad_args=(X, Y), prox_args=(step, lbda, k))\n",
    "\n",
    "monitors = [monitor_pgd_l1]\n",
    "solvers = [\"PGD\"]\n",
    "plot_epochs(monitors, solvers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 9:</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Implement the accelerated proximal gradient descent (APGD) and add this solver to the monitoring plots.\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apgd(x_init, grad, prox, n_iter=100, step=0.00001, store_every=1,\n",
    "        grad_args=(), prox_args=()):\n",
    "    \"\"\"Accelerated proximal gradient descent algorithm.\"\"\"\n",
    "    x = x_init.copy()\n",
    "    y = x_init.copy()\n",
    "    t = 1.\n",
    "    x_list = []\n",
    "    for i in range(n_iter):\n",
    "        ### TODO\n",
    "        x_new = prox(y - step * grad(y, *grad_args), *prox_args)\n",
    "        t_new = (1. + np.sqrt(1. + 4. * (t ** 2))) / 2\n",
    "        y = x_new + (t - 1.) / t_new * (x_new - x)\n",
    "        x, t = x_new, t_new\n",
    "        ### END TODO\n",
    "        if i % store_every == 0:\n",
    "            x_list.append(x.copy())\n",
    "    return x, x_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbda = 0.1\n",
    "step=0.00001\n",
    "# TODO\n",
    "monitor_apgd_l2 = monitor(apgd, pobj_l2, x_min, (X, Y, lbda))\n",
    "monitor_apgd_l2.run(x_init, grad_negloglik_auto, prox_l2, n_iter, step,\n",
    "                    grad_args=(X, Y), prox_args=(step,lbda, k))\n",
    "# END TODO\n",
    "\n",
    "monitors = [monitor_pgd_l2, monitor_apgd_l2]\n",
    "solvers = [\"PGD\", \"APGD\"]\n",
    "plot_epochs(monitors, solvers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbda = 1.\n",
    "\n",
    "# TODO\n",
    "monitor_apgd_l1 = monitor(apgd, pobj_l2, x_min, (X, Y, lbda))\n",
    "monitor_apgd_l1.run(x_init, grad_negloglik_auto, prox_l2, n_iter, step,\n",
    "                    grad_args=(X, Y), prox_args=(step,lbda, k))\n",
    "# END TODO\n",
    "\n",
    "monitors = [monitor_pgd_l1, monitor_apgd_l1]\n",
    "solvers = [\"PGD\", \"APGD\"]\n",
    "plot_epochs(monitors, solvers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Application\n",
    "\n",
    "You will now apply your solver to the `wine quality` dataset. Given 11 features\n",
    "that describe certain wines (our samples), the objective it to predict the quality of the wine,\n",
    "encoded by integers between 3 and 8. Rather than using a multiclass classification\n",
    "model we're going to use a proportional odds model.\n",
    "\n",
    "Let's first inspect the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('winequality-red.csv', delimiter=';')\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quality'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.values\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1] - 3\n",
    "X.shape, y.shape, np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a basic scaling of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale\n",
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the functions above with this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_init = np.zeros(X.shape[1] + np.unique(y).size - 1)\n",
    "x_init[:np.unique(y).size - 1] = np.arange(np.unique(y).size - 1)\n",
    "Y = binarize(y)\n",
    "\n",
    "print(negloglik(x_init, X=X, Y=Y))\n",
    "print(grad_negloglik_auto(x_init, X=X, Y=Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to facilitate our experiment we're going to write a full scikit-learn estimator.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 10:</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Implement the `fit` method from the estimator in the next cell\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "\n",
    "class ProportionalOdds(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"scikit-learn estimator for the proportional odds model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lbda : float\n",
    "        The regularization parameter\n",
    "    penalty : 'l1' | 'l2'\n",
    "        The type of regularization to use.\n",
    "    max_iter : int\n",
    "        The number of iterations / epochs to do on the data.\n",
    "    solver : 'pgd' | 'apgd' | 'lbfgs'\n",
    "        The type of regularization to use.\n",
    "        'lbfgs' is only supported with penalty='l2'.\n",
    "        \n",
    "    Attributes\n",
    "    ----------\n",
    "    alpha_ : ndarray, (n_classes - 1,)\n",
    "        The alphas.\n",
    "    beta_ : ndarray, (n_features,)\n",
    "        The regression coefficients.\n",
    "    \"\"\"\n",
    "    def __init__(self, lbda=1., penalty='l2', max_iter=2000,\n",
    "                 solver='lbfgs'):\n",
    "        self.lbda = lbda\n",
    "        self.penalty = penalty\n",
    "        self.max_iter = max_iter\n",
    "        self.solver = solver\n",
    "        assert self.penalty in ['l1', 'l2']\n",
    "        assert self.solver in ['pgd', 'apgd', 'lbfgs'] \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit method\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The features.\n",
    "        y : ndarray, shape (n_samples,)\n",
    "            The target. Must be integers between 0 and n_classes - 1.\n",
    "        \"\"\"\n",
    "        n_classes = int(np.max(y)) + 1\n",
    "        assert np.all(np.unique(y) == np.arange(n_classes))\n",
    "        Y = binarize(y)\n",
    "        n_samples, n_features = X.shape\n",
    "        # TODO\n",
    "        x_init = np.zeros(n_classes + n_features - 1)\n",
    "        x_init[:np.unique(y).size - 1] = np.arange(np.unique(y).size - 1)\n",
    "        \n",
    "        if self.penalty == 'l2':\n",
    "            prox = prox_l2\n",
    "        elif self.penalty == 'l1':\n",
    "            prox = prox_l1\n",
    "            \n",
    "        if self.solver == 'pgd':\n",
    "            x, _ = pgd(x_init,\n",
    "                    grad_negloglik_auto, \n",
    "                    prox, \n",
    "                    n_iter = self.max_iter, \n",
    "                    grad_args=(X, Y), \n",
    "                    prox_args=(0.00001, self.lbda, n_classes))\n",
    "            \n",
    "        elif self.solver == 'apgd':\n",
    "            x, _ = apgd(x_init,\n",
    "                        grad_negloglik_auto, \n",
    "                        prox, \n",
    "                        n_iter = self.max_iter, \n",
    "                        grad_args=(X, Y), \n",
    "                        prox_args=(0.00001, self.lbda, n_classes))\n",
    "        \n",
    "        elif self.solver == 'lbfgs':\n",
    "            x = proportional_odds_lbfgs_l2(X, y, self.lbda)\n",
    "        \n",
    "        # END TODO\n",
    "        self.params_ = x\n",
    "        self.alpha_ = eta.cumsum()\n",
    "        self.beta_ = beta\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict method\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_pred : ndarray, shape (n_samples,)\n",
    "            The predicted target.\n",
    "        \"\"\"\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict proba method\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray, shape (n_samples, n_features)\n",
    "            The features.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        y_proba : ndarray, shape (n_samples, n_classes)\n",
    "            The predicted probabilities.\n",
    "        \"\"\"\n",
    "        return predict_proba(self.params_, X)\n",
    "\n",
    "for solver in ['pgd', 'apgd', 'lbfgs']:\n",
    "    clf = ProportionalOdds(lbda=1., penalty='l2', max_iter=100, solver=solver)\n",
    "    clf.fit(X, y)\n",
    "    print('Solver with L2: %s   -   Score : %s' % (solver, clf.score(X, y)))\n",
    "\n",
    "for solver in ['pgd', 'apgd']:\n",
    "    clf = ProportionalOdds(lbda=1., penalty='l1', max_iter=100, solver=solver)\n",
    "    clf.fit(X, y)\n",
    "    print('Solver with L1: %s   -   Score : %s' % (solver, clf.score(X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>QUESTION 11:</b>\n",
    "    <ul>\n",
    "    <li>\n",
    "        Compare the cross-validation performance of your model with a multinomial\n",
    "        logistic regression model that ignores the order between the classes. You will comment your results.\n",
    "    </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# TODO\n",
    "clf1 = ProportionalOdds(lbda=1., \n",
    "                        penalty='l2', \n",
    "                        max_iter=100, \n",
    "                        solver='apgd')\n",
    "\n",
    "clf2 = LogisticRegression(penalty='l2',\n",
    "                          C=1.0, \n",
    "                          solver='lbfgs', \n",
    "                          max_iter=100, \n",
    "                          multi_class='multinomial')\n",
    "\n",
    "\n",
    "scoresPO = cross_val_score(clf1, X, y, cv=5)\n",
    "print(\"scores PO\")\n",
    "print(scoresPO)\n",
    "print(\"Accuracy for PO: %0.2f (+/- %0.2f)\" % (scoresPO.mean(), scoresPO.std() * 2))\n",
    "\n",
    "scoresLR = cross_val_score(clf2, X, y, cv=5)\n",
    "print(\"scores LR\")\n",
    "print(scoresLR)\n",
    "print(\"Accuracy for LR: %0.2f (+/- %0.2f)\" % (scoresLR.mean(), scoresLR.std() * 2))\n",
    "# END TODO"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
