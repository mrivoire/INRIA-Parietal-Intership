{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frank-Wolfe algorithm on constrained Lasso problem\n",
    "\n",
    "Author: Alexandre Gramfort\n",
    "\n",
    "Problem considered is:\n",
    "\n",
    "$$\n",
    "\\min \\|Ax-b\\|^2  s.t. \\|x\\|_1 \\leq r\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 30\n",
    "n_features = 40\n",
    "nnz = n_features // 10  # number of non-zeros in the true solution\n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "A = rng.randn(n_samples, n_features)\n",
    "x_true = np.concatenate((np.ones(nnz), -np.ones(nnz), -np.zeros(n_features - 2*nnz)))\n",
    "\n",
    "noise = 0.1 * rng.randn(n_samples)\n",
    "b = A.dot(x_true) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.stem(x_true, use_line_collection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_frank_wolfe(A, b, r, max_iter, use_linesearch, verbose=True):\n",
    "    x = np.zeros(A.shape[1])\n",
    "    Ax = np.dot(A, x)\n",
    "    pobj = []\n",
    "    for k in range(1, max_iter):\n",
    "        # call the LMO\n",
    "        i = np.argmax(np.abs(np.dot(A.T, Ax - b)))\n",
    "\n",
    "        step_sign = np.sign(np.dot(A[:, i].T, b - Ax))  # sign of -gradF[i]\n",
    "        s = np.zeros(n_features)\n",
    "        s[i] = step_sign * r\n",
    "        As = s[i] * A[:, i]  # = the i-th column of the design matrix A\n",
    "\n",
    "        if use_linesearch:  # line-search on the univariate quadratic problem in gamma\n",
    "            As_minus_Ax = As - Ax;\n",
    "            gamma = np.dot(As_minus_Ax.T, b - Ax) / np.dot(As_minus_Ax, As_minus_Ax)\n",
    "            gamma = max(0, min(1, gamma))  # project in [0, 1]\n",
    "        else:\n",
    "            gamma = 2. / (k + 2.)\n",
    "\n",
    "        x = (1. - gamma) * x + gamma * s  # do the FW step\n",
    "        Ax = (1 - gamma) * Ax + gamma * As  # lazy update of Ax\n",
    "\n",
    "        f_at_x = linalg.norm(Ax - b)**2 / 2.\n",
    "        if verbose:\n",
    "            print('k=%02d - f=%f - i=%d - gamma=%1.3f - ||x_k||_1=%1.3f' %\n",
    "                  (k, f_at_x, i, gamma, np.sum(np.abs(x))));\n",
    "\n",
    "        pobj.append(f_at_x)\n",
    "\n",
    "    return pobj, x\n",
    "\n",
    "r = 1.  # the regularization constraint imposed on the l_1-norm\n",
    "pobj_ls, x = lasso_frank_wolfe(A, b, r, max_iter=20, use_linesearch=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pobj_ls, x = lasso_frank_wolfe(A, b, r, max_iter=100,\n",
    "                               use_linesearch=False, verbose=False)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(9, 5))\n",
    "ax1.plot(pobj_ls)\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Objective')\n",
    "\n",
    "ax2.stem(x_true, linefmt='k-', label='True', use_line_collection=True)\n",
    "ax2.stem(x, linefmt='r-', label='Estimated', use_line_collection=True)\n",
    "ax2.set_xlabel('Features')\n",
    "ax2.set_ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at convergence rates\n",
    "\n",
    "First compute $f^*$ by running solver many iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pobj, _ = lasso_frank_wolfe(A, b, r, max_iter=10000, use_linesearch=True, verbose=False)\n",
    "f_star = np.min(pobj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot objective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100\n",
    "pobj_ls, _ = lasso_frank_wolfe(A, b, r, max_iter=max_iter,\n",
    "                               use_linesearch=True, verbose=False)\n",
    "pobj_no_ls, _ = lasso_frank_wolfe(A, b, r, max_iter=max_iter,\n",
    "                                  use_linesearch=False, verbose=False)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(9, 4))\n",
    "ax1.plot(pobj_ls, label='linesearch')\n",
    "ax1.plot(pobj_no_ls, label='no linesearch')\n",
    "ax1.set_xlabel('Iteration')\n",
    "ax1.set_ylabel('Objective')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(np.log10(pobj_ls[:-1] - f_star), label='linesearch')\n",
    "ax2.plot(np.log10(pobj_no_ls[:-1] - f_star), label='no linesearch')\n",
    "ax2.set_xlabel('Iteration')\n",
    "ax2.set_ylabel('$\\log_{10}(f(x) - f(x^*)$')\n",
    "ax2.legend()\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE:</b>\n",
    "     <ul>\n",
    "      <li>Change the conditioning of the problem, the sparsity level and observe how it affects the rate of convergence.</li>\n",
    "      <li>Implement FW for L1 constrained logistic regression</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
