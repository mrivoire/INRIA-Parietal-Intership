{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coordinate descent for least squares with non-convex regularization\n",
    "\n",
    "Author: Alexandre Gramfort, Joseph Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prox_collection import l22_prox, l1_prox, l0_prox, scad_prox, mcp_prox, \\\n",
    "    log_prox, sqrt_prox, enet_prox\n",
    "from prox_collection import l22_objective, l1_objective, l0_objective, \\\n",
    "    scad_objective, mcp_objective, log_objective, sqrt_objective, \\\n",
    "    enet_objective\n",
    "from prox_collection import l22_pen, l1_pen, l0_pen, \\\n",
    "    scad_pen, mcp_pen, log_pen, sqrt_pen, \\\n",
    "    enet_pen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-2, 2, 100)\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "ax1.plot(x, list(map(lambda y: mcp_pen(y, threshold=0.5, gamma=2.2), x)))\n",
    "ax2.plot(x, list(map(lambda y: mcp_prox(y, threshold=0.5, gamma=2.2), x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate simulated data\n",
    "\n",
    "$y = xw+b+noise$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "n_samples, n_features = 300, 100\n",
    "A = np.random.randn(n_samples, n_features)\n",
    "x_true = np.zeros(n_features)\n",
    "x_true[5] = 3.\n",
    "x_true[12] = -2.\n",
    "x_true[40] = 5.\n",
    "y = np.dot(A, x_true)\n",
    "y += 0.3 * np.random.randn(n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.stem(x_true, use_line_collection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclic proximal coordinate descent\n",
    "\n",
    "Solve:\n",
    "\n",
    "$\\min_x \\frac{1}{2} \\|y - Ax\\|^2 + \\alpha\\ {\\rm pen}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 400.\n",
    "\n",
    "def pen(x):\n",
    "    return np.array(list(map(lambda y: l1_pen(y, threshold=0.5), x)))\n",
    "\n",
    "def objective(x):\n",
    "    return 0.5 * linalg.norm(A.dot(x) - y)**2 + alpha * np.sum(pen(x))\n",
    "\n",
    "def prox(x, threshold):\n",
    "    return l1_prox(x, threshold=threshold)\n",
    "\n",
    "if True:\n",
    "    def pen(x):\n",
    "        return np.array(list(map(lambda y: mcp_pen(y, threshold=0.5, gamma=1.2), x)))\n",
    "\n",
    "    def objective(x):\n",
    "        return 0.5 * linalg.norm(A.dot(x) - y)**2 + alpha * np.sum(pen(x))\n",
    "\n",
    "    def prox(x, threshold):\n",
    "        return mcp_prox(x, threshold=threshold, gamma=1.2)\n",
    "\n",
    "\n",
    "Li = np.sum(A * A, axis=0)\n",
    "n_iter = 10 * n_features\n",
    "\n",
    "x_hat = np.zeros_like(x)\n",
    "objs = list()\n",
    "for k in range(n_iter):\n",
    "    i = k % n_features\n",
    "    x_hat[i] = np.dot(A[:, i].T, y - np.dot(A, x_hat) + x_hat[i] * A[:, i])\n",
    "    x_hat[i] /= Li[i]\n",
    "    x_hat[i] = prox(x_hat[i], alpha / Li[i])\n",
    "    objs.append(objective(x_hat))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "ax1.plot(objs)\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('objective')\n",
    "ax2.stem(x_true, linefmt='k-', markerfmt='ko', basefmt='k-', use_line_collection=True)\n",
    "ax2.stem(x_hat, linefmt='r-', markerfmt='ro', basefmt='r-', use_line_collection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### or written in a more generic manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_i(x, i):\n",
    "    return np.dot(A[:, i].T, np.dot(A, x) - y)\n",
    "\n",
    "Li = np.sum(A * A, axis=0)\n",
    "\n",
    "n_iter = 10 * n_features\n",
    "\n",
    "x_hat = np.zeros_like(x)\n",
    "objs = list()\n",
    "for k in range(n_iter):\n",
    "    i = k % n_features\n",
    "    x_hat[i] -= 1. / Li[i] * gradient_i(x_hat, i)\n",
    "    x_hat[i] = prox(x_hat[i], alpha / Li[i])\n",
    "    objs.append(objective(x_hat))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\n",
    "ax1.plot(objs)\n",
    "ax1.set_xlabel('iteration')\n",
    "ax1.set_ylabel('objective')\n",
    "ax2.stem(x_true, linefmt='k-', markerfmt='ko', basefmt='k-', use_line_collection=True)\n",
    "ax2.stem(x_hat, linefmt='r-', markerfmt='ro', basefmt='r-', use_line_collection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE:</b>\n",
    "     <ul>\n",
    "      <li>Modify the code to use L0/Hard thresholding or SCAD instead of MCP.</li>\n",
    "      <li>How would you evaluate what works best?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
