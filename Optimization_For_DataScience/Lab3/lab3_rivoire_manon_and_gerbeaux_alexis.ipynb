{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "name": "lab3_rivoire_manon_and_gerbeaux_alexis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JnU58e8a2lLS"
      },
      "source": [
        "# Short Lab 3 : Proximal/cyclic/greedy coordinate descent\n",
        "\n",
        "#### Authors: A. Gramfort, M. Massias, P. Ablin\n",
        "\n",
        "## Aim\n",
        "\n",
        "The aim of this material is to code \n",
        "- cyclic and greedy coordinate descent for ordinary least squares (OLS)\n",
        "- proximal coordinate descent for sparse Logistic regression\n",
        "\n",
        "## VERY IMPORTANT\n",
        "\n",
        "- This work **must be done by pairs of students**.\n",
        "- **Each** student must send their work **before the 11th of november at 23:59**, using the **moodle platform**.\n",
        "- This means that **each student in the pair sends the same file**\n",
        "- On the moodle, in the \"Optimization for Data Science\" course, you have a \"devoir\" section called **Rendu TP du 5 novembre 2018**. This is where you submit your jupyter notebook file. \n",
        "- The **name of the file must be** constructed as in the next cell\n",
        "\n",
        "# Gentle reminder: no evaluation if you don't respect this EXACTLY\n",
        "\n",
        "### How to construct the name of your file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xT0G-LHg2lLU",
        "outputId": "5b456f75-78c3-4b7a-9f85-53a9ee40025d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Change here using YOUR first and last names\n",
        "fn1 = \"manon\"\n",
        "ln1 = \"rivoire\"\n",
        "fn2 = \"alexis\"\n",
        "ln2 = \"gerbeaux\"\n",
        "\n",
        "filename = \"_\".join(map(lambda s: s.strip().lower(), \n",
        "                        [\"lab3\", ln1, fn1, \"and\", ln2, fn2])) + \".ipynb\"\n",
        "print(filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lab3_rivoire_manon_and_gerbeaux_alexis.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YuOVDigk2lLX",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy.linalg import norm\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qbkx4-9h2lLa",
        "colab": {}
      },
      "source": [
        "# the usual functions:\n",
        "\n",
        "from numpy.random import multivariate_normal\n",
        "from scipy.linalg.special_matrices import toeplitz\n",
        "from numpy.random import randn\n",
        "\n",
        "\n",
        "def simu(coefs, n_samples=1000, corr=0.5, for_logreg=False):\n",
        "    n_features = len(coefs)\n",
        "    cov = toeplitz(corr ** np.arange(0, n_features))\n",
        "    A = multivariate_normal(np.zeros(n_features), cov, size=n_samples)\n",
        "    b = A.dot(coefs) + randn(n_samples)\n",
        "    if for_logreg:\n",
        "        b = np.sign(b)\n",
        "    return A, b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DyDqCprl2lLb"
      },
      "source": [
        "## Part 1: Ordinary Least Squares\n",
        "\n",
        "\n",
        "Let $A \\in \\mathbb{R}^{n \\times p}$, $y \\in \\mathbb{R}^n$.\n",
        "We want to use coordinate descent to solve:\n",
        "    $$\\hat w \\in  \\mathrm{arg \\, min \\,} \\frac 12 \\Vert Aw - b \\Vert ^2 $$\n",
        "\n",
        "We ask you to code:\n",
        "- cyclic coordinate descent: at iteration $t$, update feature $j = t \\mod p$\n",
        "- greedy coordinate descent: at iteration $t$, update feature having the largest partial gradient in magnitude, ie $j = \\mathrm{arg\\, max \\,}_{i} \\vert \\nabla_i f(w_t) \\vert$.\n",
        "\n",
        "\n",
        "**WARNING**: You must do this in a clever way, ie such that $p$ updates cost the same as one update of GD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HiO7cxjL2lLc",
        "colab": {}
      },
      "source": [
        "n_features = 100\n",
        "np.random.seed(1970)\n",
        "coefs = np.random.randn(n_features)\n",
        "\n",
        "A, b = simu(coefs, n_samples=1000, for_logreg=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qDI5CerD2lLe",
        "colab": {}
      },
      "source": [
        "def cyclic_cd(A, b, n_iter):\n",
        "    n_samples, n_features = A.shape\n",
        "    all_objs = []\n",
        "    \n",
        "    w = np.zeros(n_features)\n",
        "    residuals = b - A.dot(w)\n",
        "    \n",
        "    # TODO\n",
        "    lips_const = np.linalg.norm(A, axis=0) ** 2 ## vecteur des normes au carré des vecteurs colonnes Ai. nx1 dimensional vector containing a Lipschitz constant specific to each of the n features (that is specific to each of the n coordinates)\n",
        "    # END TODO\n",
        "    \n",
        "    for t in range(n_iter):\n",
        "        j = t % n_features # the index of the coordinate to update corresponds to the rest in the Euclidean Division of the number of iterations by the number of features\n",
        "        # TODO\n",
        "        old_w_j = w[j].copy()\n",
        "        step = 1/lips_const[j]\n",
        "        grad = (A[:,j].T).dot(residuals)\n",
        "        w[j] += step*grad\n",
        "        # update residuals: \n",
        "        # We only update the jth coordinate of the vector of residuals since only the jth coordinate of the vector of weights has been modified\n",
        "        residuals += np.dot(A[:,j], old_w_j - w[j]) ##écrire r_t+1 - r_t et écrire en fct de w_t+1 - w_t\n",
        "        # END TODO\n",
        "        \n",
        "        if t % n_features == 0:\n",
        "            all_objs.append((residuals ** 2).sum() / 2.)\n",
        "    return w, np.array(all_objs)\n",
        "\n",
        "def greedy_cd(A, b, n_iter):\n",
        "    n_samples, n_features = A.shape\n",
        "    all_objs = []\n",
        "    \n",
        "    w = np.zeros(n_features)\n",
        "    \n",
        "    gradient = A.T.dot(A.dot(w) - b)\n",
        "    gram = A.T.dot(A)  # you will need this to keep the gradient up to date\n",
        "    \n",
        "    # TODO\n",
        "    lips_const = np.linalg.norm(A, axis=0) ** 2\n",
        "    # END TODO \n",
        "    \n",
        "    for t in range(n_iter):\n",
        "        # TODO\n",
        "        # choose feature j to update: \n",
        "        j = np.argmax(np.abs(gradient))\n",
        "        old_w_j = w[j].copy()\n",
        "        w[j] -= (1/lips_const[j])*gradient[j] ##We only update the jth coordinate of the vector of weights\n",
        "        # update gradient:\n",
        "        gradient += gram[:,j]*(w[j] - old_w_j) ##We only update the jth coordinate of the gradient vector since we only have updated the jth coordinate of the vector of weights\n",
        "        # END TODO\n",
        "        if t % n_features == 0:\n",
        "            all_objs.append(0.5 * np.linalg.norm(A.dot(w) - b) ** 2)\n",
        "    \n",
        "    return w, np.array(all_objs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l9mklLup2lLg",
        "outputId": "c7d288ee-21d1-4957-d3f5-b1cb056d561c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "w_min_cyclic_cd, obj_w_cyclic_cd = cyclic_cd(A, b, 10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 220 ms, sys: 5.94 ms, total: 226 ms\n",
            "Wall time: 428 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XEV-3ROJ2lLh",
        "outputId": "3626e6bb-2d4b-4841-f88c-bceb2e86d57c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time \n",
        "w_min_greedy_cd, obj_w_greedy_cd = greedy_cd(A, b, 10000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 265 ms, sys: 24 ms, total: 289 ms\n",
            "Wall time: 160 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jeFufGMY2lLj"
      },
      "source": [
        "**Questions :**\n",
        "- compute a precise minimum with your favorite solver\n",
        "- compare the performance of cyclic and greedy CD\n",
        "\n",
        "- from a practical point of view, could you use greedy CD for ridge logistic regression? to solve OLS, but with 100,000 features? Explain your answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "07QD-ZAu2lLk"
      },
      "source": [
        "### Compute a precise minimum with your favorite solver"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WtRnDXvJ2lLk"
      },
      "source": [
        "Minimum computed with l-bfgs solver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ymieF3wj2lLl",
        "outputId": "5d1ecb7f-2084-4cb2-c448-2da0fb5ff5fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "\n",
        "def grad(w, A, b):\n",
        "    return A.T.dot(A.dot(w) - b)\n",
        "    \n",
        "def loss(w, A, b):\n",
        "    return norm(A.dot(w) - b) ** 2 / 2\n",
        "    \n",
        "w_init = np.zeros(n_features)\n",
        "\n",
        "w_min, f_min, _ = fmin_l_bfgs_b(loss, w_init, grad, args=(A, b), pgtol=1e-30, factr=1e-30)\n",
        "\n",
        "\n",
        "print(f_min)\n",
        "print(w_min) #best solution to the opti pb so we will compare the other minimizers to this one assuming it's the 'real' solution\n",
        "print(norm(grad(w_min, A, b)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "466.38497653376567\n",
            "[-0.00772678  1.1722585  -0.26704868  0.70004526  0.6395015   0.76854499\n",
            " -0.6715586  -1.16392572  0.04667156 -0.19553794  1.90429109  1.40048949\n",
            "  0.49102095 -0.84138107 -1.44433611  1.60925495 -1.04829763 -0.46741439\n",
            " -1.56420944 -0.5049202   0.24166775 -0.17082697 -1.8685883  -1.45447257\n",
            "  0.33296101  0.95929147  0.55429929  1.14589981 -0.06046799 -0.4264222\n",
            "  2.02338434 -1.57558751 -0.23636267 -1.33706995  1.19093151 -0.39092006\n",
            "  0.86724978  0.26923088 -0.85206818 -0.07024918 -0.3642956  -0.00576861\n",
            " -1.56783243 -1.92839434 -1.53959864 -0.38137738 -0.58731018 -1.72603575\n",
            "  0.39133318 -0.28659137  0.2162589  -0.22917056  0.93575223 -0.49609361\n",
            " -0.32023458  1.05655835  1.01878796  0.98860962 -0.81709049 -0.95800001\n",
            " -1.32897382  0.06565243  0.46755933 -1.15942364  0.3859497  -0.3170157\n",
            "  0.47849    -0.32858091 -0.66056608 -1.01725307  0.53129895  2.02183154\n",
            "  0.47129171 -0.90273392  1.39594999  0.03366695  0.35948564  0.3089695\n",
            " -0.30875605  1.39495298 -0.05198068 -0.43630584  0.73357994 -1.97871654\n",
            " -2.16314621 -0.9056383  -0.85756951  0.37498962 -1.3044168   1.27238395\n",
            "  0.36676304 -0.77223172 -0.56330661  1.34435575 -0.19601597 -0.2085148\n",
            " -1.14008843 -0.13855494  0.78140583  1.02761541]\n",
            "8.507196070970822e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MT6CPs0R2lLn"
      },
      "source": [
        "Other minimim computed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9IFV0eEf2lLn",
        "outputId": "554a01a5-8cab-4cd9-f81c-4b617b6bc613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "w_min_ols,_,_,_, = np.linalg.lstsq(A, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Oc2GMzOf2lLp"
      },
      "source": [
        "### Compare the performance of cyclic and greedy CD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YJhudUdy2lLq"
      },
      "source": [
        "First, let compare the difference between the minimum computed with the solvers above and the minimum obtained with cyclic coordinate descent and greedy coordinate descent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5QaA06ZK2lLq"
      },
      "source": [
        "Pour la descente par coordonnée cyclique :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JODdcl2z2lLr",
        "outputId": "a9be473d-a51b-473c-b5fe-ed75e720d6cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Distance au minimiseur(ols) : %e\" %np.linalg.norm(w_min_ols - w_min_cyclic_cd))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance au minimiseur(ols) : 3.359763e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ALaaXrnM2lLt",
        "outputId": "5a0c1d1b-c5f0-4c3c-a91c-de6826677f25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Distance au minimiseur(l-bfgs) : %e\" %np.linalg.norm(w_min - w_min_cyclic_cd))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance au minimiseur(l-bfgs) : 1.535013e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QzKPM6W_2lLv",
        "outputId": "07c4e22e-3570-43c8-9934-f83676ae349a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Distance au minimum(l-bfgs) : %e\" %np.linalg.norm(f_min - obj_w_cyclic_cd[-1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance au minimum(l-bfgs) : 5.115908e-13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nqaxNKtg2lLx"
      },
      "source": [
        "Pour la descente par coordonnée greedy :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Imc9mPI42lLx",
        "outputId": "f507f54b-da60-403f-b6dd-bc6bda6d110d",
        "colab": {}
      },
      "source": [
        "print(\"Distance au minimiseur(ols) : %e\" %np.linalg.norm(w_min_ols - w_min_greedy_cd))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance au minimiseur(ols) : 3.519856e-14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nd6zmONM2lLz",
        "outputId": "ea619e6f-8a15-4ccb-a31c-463e54d476e4",
        "colab": {}
      },
      "source": [
        "print(\"Distance au minimiseur(l-bfgs) : %e\" %np.linalg.norm(w_min - w_min_greedy_cd))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance au minimiseur(l-bfgs) : 1.535012e-08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AhdbSL4n2lL1",
        "outputId": "cf9857c1-6eba-4753-ae52-e59eed2010d2",
        "colab": {}
      },
      "source": [
        "print(\"Distance au minimum(l-bfgs) : %e\" %np.linalg.norm(f_min - obj_w_greedy_cd[-1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Distance au minimum(l-bfgs) : 2.273737e-13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BNklJ_q_2lL3"
      },
      "source": [
        "Comparons maintenant les vitesses de convergence des deux méthodes de descente par coordonée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cYj8s-Gt2lL3",
        "outputId": "af882ac1-bb2f-4491-d6ff-ff63d6220769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "#import seaborn as sns\n",
        "y = obj_w_greedy_cd - f_min\n",
        "z = obj_w_cyclic_cd - f_min\n",
        "\n",
        "x = np.arange(1, len(y)+1)\n",
        "\n",
        "plt.plot(x, y, label='greedy_cd')\n",
        "plt.plot(x, z, label='cyclic_cd')\n",
        "plt.yscale('log')\n",
        "plt.title(\"Comparaison des objectifs en fonction du nombre d'itération\")\n",
        "plt.xlabel('n_iter')\n",
        "plt.ylabel('f obj')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ayCq_r8p2lL5"
      },
      "source": [
        "Les deux méthodes de descente par coordonnées sont linéaires en échelle logarithmique. D'après la proposition de Beck and Tetruashvilli (pour cycllic_cd) la convergence est en 1 sur le nombre d'itérations. En échelle logarithmique (en base 10) il est donc normal de retrouver des convergences linéaires.<br>\n",
        "La descente par coordonnées greedy est un peu plus rapide que la cyclique en termes d'itérations. Ceci s'explique car l'algo greedy sélectionne les coordonnées pour lesquelles le gradient est le plus grand en premier. Cependant, pour la méthode greedy le temps d'une itération est plus grand car il doit calculer l'argmax du gradient. On remarque déjà une différence de temps pour 5000 ou 50000 itérations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Th6_ORQj2lL6"
      },
      "source": [
        "### From a practical point of view, could you use greedy CD for\n",
        "- ridge logistic regression?\n",
        "- to solve OLS, but with 100,000 features?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LA0qVrcz2lL7"
      },
      "source": [
        "A cause de la recherche du maximum du gradient sur les features, cette opération peut devenir vite très coûteuse comparé à l'algorithme cyclique qui ne cherche pas à calculer cela et itère sur chaque feature à tour de rôle. En effet avec 100,000 features, il est en pratique impossible de se servir de l'algo de descente par coordonnéees greedy.<br>\n",
        "La constante de Lipschitz est un peu différente avec la pénalisation ridge. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "iABiKVr52lL8"
      },
      "source": [
        "## Part 2: Sparse Logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WMCyyajz2lL-"
      },
      "source": [
        "### An important result\n",
        "\n",
        "Remember: we are solving \n",
        "$$\\hat w \\in \\mathrm{arg \\, min} \\sum_{i=1}^{n} \\mathrm{log} ( 1 + e^{- y_i w^\\top x_i} )  + \\lambda \\Vert w \\Vert_1$$\n",
        "1) Assuming uniqueness of the solution, show that:\n",
        "$$ \\lambda \\geq \\lambda_{max} \\Leftrightarrow \\hat w = 0$$\n",
        "where $\\lambda_{max} := \\frac 12 \\Vert X^\\top y \\Vert_{\\infty}$.\n",
        "\n",
        "\n",
        "You will need the following beautiful result: for any $w =(w_1, \\dots, w_p) \\in \\mathbb{R}^p$, the subdifferential of the L1 norm at $w$ is:\n",
        "\n",
        "$$\\partial \\Vert \\cdot \\Vert_1 (w) = \\partial \\vert \\cdot \\vert (w_1)  \\times \\dots \\times \\partial \\vert \\cdot \\vert (w_p) $$\n",
        "where $\\times$ is the Cartesian product between sets,\n",
        "and $$ \\partial \\vert \\cdot \\vert (w_j) = \n",
        "\\begin{cases} &w_j / |w_j| &\\mathrm{if} \\quad w_j \\neq 0, \n",
        "         \\\\ & [-1, 1] &\\mathrm{otherwise.} \n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "\n",
        "(it should now be easy to find $\\partial \\Vert \\cdot \\Vert_1 (\\mathbf{0}_p)$)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0_czSz6v2lL_"
      },
      "source": [
        "<font color='blue'>\n",
        "\n",
        "**Proof**\n",
        "\n",
        "We know : \n",
        "\\begin{equation}\n",
        "  \\hat{w} \\in arg min \\sum_{i = 1}^{n} \\log(1 + e^{-y_{i}w^{T}x_{i}}) + \\lambda \\left \\| w \\right \\|_{1} \\Leftrightarrow 0 \\in \\partial [\\sum_{i = 1}^{n} \\log(1 + e^{-y_{i}w^{T}x_{i}}) + \\lambda \\left \\| w \\right \\|_{1}](\\hat{w})\n",
        "\\end{equation}\n",
        "\n",
        "So : \n",
        "\\begin{equation}\n",
        "\\hat{w} = 0 \\Leftrightarrow 0\\in \\partial [\\sum_{i = 1}^{n} \\log(1 + e^{-y_{i}w^{T}x_{i}}) + \\lambda \\left \\| w \\right \\|_{1}](0)\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\Leftrightarrow 0 \\in \\sum_{i = 1}^{n} \\nabla \\log(1 + e^{-y_{i}w^{T}x_{i}})(0) + \\lambda \\partial \\left \\| w \\right \\|_{1}(0)\n",
        "\\end{equation}\n",
        "\n",
        "Yet : \n",
        "\n",
        "\\begin{equation}\n",
        "  \\nabla \\log(1 + e^{-y_{i}w^{T}x_{i}})(0) = -\\frac{x_{i}^{T}y_{i}}{1+e^{y_{i}w^{T}x_{i}}}(0) = -\\frac{x_{i}^{T}y_{i}}{2}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation} \n",
        "\\sum_{i = 1}^{n} \\nabla \\log(1 + e^{-y_{i}w^{T}x_{i}})(0) = -\\frac{X^\\top y}{2}\n",
        "\\end{equation}\n",
        "\n",
        "And : \n",
        "\n",
        "\\begin{equation}\n",
        "\\partial \\left \\| w \\right \\|_{1}(0) = [-1,1]^{p}\n",
        "\\end{equation}\n",
        "\n",
        "Thus : \n",
        "\n",
        "\\begin{equation}\n",
        "\\hat{w} = 0 \\Leftrightarrow 0 \\in -\\frac{X^\\top y}{2} + \\lambda [-1,1]^{p}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\Leftrightarrow X^\\top y \\in 2\\lambda [-1,1]^{p}\n",
        "\\end{equation}\n",
        "\n",
        "Therefore : \n",
        "\n",
        "\\begin{equation}\n",
        "  \\forall j \\in {1, \\ldots, p},\\ -2\\lambda \\leq (X^\\top y)_{j} \\leq 2\\lambda\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "  \\Leftrightarrow \\forall j \\in {1, \\ldots, p},\\ |(X^\\top y)_{j}| \\leq 2\\lambda\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "  \\Leftrightarrow \\ max_{1 \\leq j \\leq p} |(X^\\top y)_{j}| \\leq 2\\lambda \n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "  \\Leftrightarrow \\left \\| X^\\top y \\right \\|_{\\infty} \\leq 2\\lambda \n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "  \\Leftrightarrow \\lambda \\geq \\frac{\\left \\| X^\\top y \\right \\|_{\\infty}}{2} := \\lambda_{max}\n",
        "\\end{equation}\n",
        "\n",
        "So we have shown that : \n",
        "\n",
        "\\begin{equation}\n",
        "  \\hat{w} = 0 \\Leftrightarrow \\lambda \\geq \\lambda_{max} := \\frac 12 \\Vert X^\\top y \\Vert_{\\infty}\n",
        "\\end{equation}\n",
        "\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PYxBDWeN2lMC"
      },
      "source": [
        "2) Show that for sparse Logistic regression the coordinate-wise Lipschitz constant of the smooth term, $\\gamma_j$, can be taken equal to $\\Vert X_j \\Vert^2 / 4$, where $X_j$ denotes the $j$-th column of $X$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TvBp2YYc2lME"
      },
      "source": [
        "<font color='blue'>\n",
        "    \n",
        "**Proof**\n",
        "\n",
        "\\begin{equation}\n",
        "  f(w) = \\sum_{i = 1}^{n} \\log(1 + e^{-y_{i}w^{T}x_{i}}) = \\sum_{i = 1}^{n} \\phi(y_{i}w^{T}x_{i})\n",
        "\\end{equation}\n",
        "\n",
        "Where $\\phi$ is the following function : \n",
        "\\begin{equation}\n",
        "  \\phi(\\alpha) = \\log(1 + e^{-\\alpha})\n",
        "\\end{equation}\n",
        "    \n",
        "We would like to find an upper bound to the second derivative of $\\phi$. \n",
        "    \n",
        "$\\phi$ is $C^{\\infty}$ and we have : \n",
        "\\begin{equation}\n",
        "  \\phi''(\\alpha) = \\frac{e^{\\alpha}}{(1+e^{\\alpha})^2}\n",
        "\\end{equation}\n",
        "\n",
        "We know that : \n",
        "\\begin{equation}\n",
        "  (a + b)^2 - 4ab = a^2 + b^2 - 2ab = (a-b)^2 \\geq 0\n",
        "\\end{equation}\n",
        "\n",
        "Let's take $a = 1$ and $b = e^{\\alpha}$, then we obtain : \n",
        "\\begin{equation}\n",
        "  (1 + e^{\\alpha})^2 - 4e^{\\alpha} \\geq 0 \\\\\n",
        "  (1 + e^{\\alpha})^2 \\geq 4e^{\\alpha} \\\\\n",
        "  \\frac{e^{\\alpha}}{(1 + e^{\\alpha})^2} \\leq \\frac{1}{4}\\\\\n",
        "  \\phi''(\\alpha) \\leq \\frac{1}{4}\n",
        "\\end{equation}\n",
        "    \n",
        "And since we have $\\phi'' \\geq 0$, then we have proved that : \n",
        "\\begin{equation}\n",
        "  |\\phi''(\\alpha)| \\leq \\frac{1}{4}\n",
        "\\end{equation}\n",
        "\n",
        "Let keep in mind that by the Mean Value Inequality, we have : <br/>\n",
        "\\begin{equation}\n",
        "  \\forall a, b \\in \\mathbb{R}, |\\phi'(a) - \\phi'(b)| \\leq sup_\\alpha \\left\\lbrace|\\phi''(\\alpha)|\\right\\rbrace |a - b| \\leq \\frac14 |a - b|\n",
        "\\end{equation}\n",
        "\n",
        "Let's compute the gradient of $f$ with regards to $w$. \n",
        "\\begin{equation}\n",
        "  \\nabla f(w) = \\nabla \\left( \\sum_{i = 1}^{n} \\phi(y_{i}w^{T}x_{i}) \\right) = \\sum_{i = 1}^{n} \\nabla \\phi(y_{i}w^{T}x_{i}) = \\sum_{i = 1}^{n} \\phi'(y_{i}w^{T}x_{i})y_{i}x_{i}^{T}\n",
        "\\end{equation}\n",
        "\n",
        "Since we only updates one coordinate of the parameter's vector at a time, then we are going to rewrite the gradient of $f$ in function of the $j^{th}$ coordinate $w_{j}, \\forall j \\in \\left\\lbrack 1, p \\right\\rbrack$ <br/>\n",
        "\\begin{equation}\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | = | \\sum_{i = 1}^{n} \\phi'(y_{i}(w + te_{j})^{T}x_{i})y_{i}x_{ij} - \\sum_{i = 1}^{n} \\phi'(y_{i}w^{T}x_{i})y_{i}x_{ij}| \\\\\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | = | \\sum_{i = 1}^{n} \\left\\lbrack\\phi'(y_{i}(w + te_{j})^{T}x_{i}) - \\phi'(y_{i}w^{T}x_{i})\\right\\rbrack y_{i}x_{ij}| \\\\\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | \\leq \\sum_{i = 1}^{n} | \\phi'(y_{i}(w + te_{j})^{T}x_{i}) - \\phi'(y_{i}w^{T}x_{i}) | |y_{i}x_{ij}| \n",
        "\\end{equation} \n",
        "\n",
        "We apply the Mean Value Inequality with $a_{i} = y_{i}(w+te_{j})^{T}x_{i}$, $b_{i} = y_{i}w^{T}x_{i}$. \n",
        "\\begin{equation}\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | \\leq \\sum_{i = 1}^{n} \\frac{1}{4}| y_{i}(w+te_{j})^{T}x_{i} - y_{i}w^{T}x_{i}| |y_{i}x_{ij}| \\\\\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | \\leq \\sum_{i = 1}^{n} \\frac{1}{4}| y_{i}\\left\\lbrack(w^{T} + te_{j}^{T}) - w^{T}\\right\\rbrack x_{i} | |y_{i}x_{ij}| \\\\\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | \\leq \\frac{1}{4} \\sum_{i = 1}^{n} | y_{i} te_{j}^{T} x_{i} | |y_{i}x_{ij}| \\\\\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | \\leq \\frac{1}{4} \\sum_{i = 1}^{n} | y_{i} t x_{ij} | |y_{i}x_{ij}| \\\\\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | \\leq \\frac{1}{4} \\sum_{i = 1}^{n} |t||y_{i}x_{ij}|^{2} \\\\\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | \\leq \\frac{1}{4} \\sum_{i = 1}^{n} |t|y_{i}^{2}x_{ij}^{2} \n",
        "\\end{equation} \n",
        "\n",
        "But $\\forall i \\in \\left\\lbrack 1, n \\right\\rbrack, y_{i} \\in \\left\\lbrace -1, +1 \\right\\rbrace$, therefore we obtain : \n",
        "\\begin{equation}\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | \\leq \\frac{1}{4} \\sum_{i = 1}^{n} |t|x_{ij}^{2} \\\\\n",
        "  | \\nabla_{j} f(w + te_{j}) - \\nabla_{j} f(w) | \\leq \\frac{|t|}{4} \\sum_{i = 1}^{n} x_{ij}^{2} \\\\\n",
        "  | \\nabla_{j} L(w + te_{j}) - \\nabla_{j} L(w) | \\leq |t| \\frac{\\left \\| X_{j} \\right \\|^{2} }{4}\n",
        "\\end{equation} \n",
        "\n",
        "Thus for sparse Logistic Regression, the coordinate-wise Lipshitz constant of the smooth term, $\\gamma_{j}$, can be taken equal to  $\\Vert X_j \\Vert^2 / 4$ , where  Xj  denotes the  j -th column of  X.\n",
        "\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zldul7TL2lMF"
      },
      "source": [
        "You are now ready to code **cyclic proximal coordinate descent** for sparse Logistic regression:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MGhD00I22lMF"
      },
      "source": [
        "**WARNING**: <br>\n",
        "Lasso means linear regression (quadratic fitting term) with L1 penalty. <br>\n",
        "Sparse logistic regression means logistic regression with L1 penalty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E7aNpSYx2lMG",
        "colab": {}
      },
      "source": [
        "X, y = simu(coefs, n_samples=1000, for_logreg=True)\n",
        "lambda_max = norm(X.T.dot(y), ord= np.inf) / 2.\n",
        "lamb = lambda_max / 20.  \n",
        "# much easier to parametrize lambda as a function of lambda_max than \n",
        "# to take random values like 0.1 in previous Labs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ssnXJS2o2lMI",
        "colab": {}
      },
      "source": [
        "def sigmoid(t):\n",
        "    \"\"\"Sigmoid function\"\"\"\n",
        "    return 1. / (1. + np.exp(-t))\n",
        "\n",
        "def soft_thresh(x, u):\n",
        "    \"\"\"Soft thresholding of x at level u\"\"\"\n",
        "    return np.sign(x) * np.maximum(0., np.abs(x) - u)\n",
        "\n",
        "def cd_logreg(X, y, lamb, n_iter):\n",
        "    n_samples, n_features = X.shape\n",
        "    all_objs = np.zeros(n_iter)\n",
        "    w = np.zeros(n_features)\n",
        "    Xw = X.dot(w)\n",
        "    \n",
        "    # TODO\n",
        "    lips_const = (np.linalg.norm(X, axis=0)**2)/4\n",
        "    # END TODO\n",
        "    \n",
        "    for t in range(n_iter):\n",
        "        for j in range(n_features):\n",
        "            old_w_j = w[j]\n",
        "            \n",
        "            # TODO\n",
        "            grad_j = np.sum(- y * X[:, j] * sigmoid(-y * Xw))\n",
        "            step = 1/lips_const[j]\n",
        "            w[j] = soft_thresh(w[j] - step*grad_j, lamb*step) # proximal operator of the L1 norm corresponds to the soft thresholding function\n",
        "            \n",
        "            if old_w_j != w[j]:\n",
        "                Xw += X[:,j].dot(w[j]-old_w_j)\n",
        "            #END TODO  \n",
        "            \n",
        "        all_objs[t] = np.log(1. + np.exp(-y * Xw)).sum() + lamb * norm(w, ord=1)\n",
        "    \n",
        "    return w, all_objs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WgVNwyNv2lMK",
        "outputId": "67fb4d67-9362-40a9-df7b-e3ca0f2247bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "w_min_cd_logreg, obj_w_cd_logreg = cd_logreg(X, y, lamb, 2000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.1 s, sys: 104 ms, total: 10.2 s\n",
            "Wall time: 11.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55qxZIALMfPh",
        "colab_type": "code",
        "colab": {},
        "outputId": "040abca1-2322-456c-cd9a-ffd811c3b0fa"
      },
      "source": [
        "obj_w_cd_logreg[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "370.90370359545796"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "p-x8JTKm2lMQ"
      },
      "source": [
        "# Part 3: Real data\n",
        "\n",
        "We will compare vanilla cyclic CD and ISTA to **solve the Lasso** on a real dataset, called _leukemia_."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Vr5jWQOL2lMQ",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "leuk = fetch_openml(\"leukemia\")\n",
        "\n",
        "X = np.asfortranarray(leuk.data)\n",
        "y = np.ones(leuk.target.shape)\n",
        "y[leuk.target == leuk.target[0]] = -1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HmGYPQKR2lMS",
        "outputId": "96593301-0c5a-4117-935c-d45adf6e1514",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "lambda_max_lasso = norm(X.T.dot(y), ord=np.inf)\n",
        "lambd = lambda_max_lasso / 5.\n",
        "\n",
        "n, p = X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(72, 7129)\n",
            "(72,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rD-FxEhj2lMV"
      },
      "source": [
        "Code:\n",
        "- a simple proximal gradient solver for the Lasso\n",
        "- a prox CD solver for the Lasso\n",
        "and compare them on this dataset. \n",
        "Do the plots in terms of epochs, not updates (to be fair to CD)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S3kOTYXU2lMW"
      },
      "source": [
        "The problems we want to minimize take the form:\n",
        "$$\n",
        "\\arg\\min_w f(w) + \\lambda \\,R(w)\n",
        "$$\n",
        "where :\n",
        "$$\n",
        "f(w) = \\frac{1}{2} \\| y - X w \\|_2^2,\n",
        "$$\n",
        "and :\n",
        "$$\n",
        "R(w) = \\|w\\|_1\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jF4R-pQ52lMW"
      },
      "source": [
        "### Proximal gradient solver for the Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDei0M2G2lMX",
        "colab": {}
      },
      "source": [
        "def prox_L1(x, lmbd):\n",
        "    \"\"\"Proximal operator for the L1 at x\"\"\"\n",
        "    return np.sign(x)*np.maximum(np.abs(x)-lmbd,0)\n",
        "\n",
        "def L1_norm(x, lmbd):\n",
        "    \"\"\"Value of the L1 penalization at x\"\"\"\n",
        "    return lmbd*np.linalg.norm(x,ord=1)\n",
        "\n",
        "def loss_linreg(w):\n",
        "    \"\"\"Least squares loss\"\"\"\n",
        "    return (1/2)*np.linalg.norm(y-np.dot(X,w), ord=2)**2\n",
        "\n",
        "def grad_linreg(w):\n",
        "    \"\"\"Least squares gradient\"\"\"\n",
        "    return -np.dot(X.T, y-np.dot(X,w))\n",
        "#from scipy.optimize import check_grad\n",
        "#check_grad(loss_linreg, grad_linreg, randn(p))\n",
        "\n",
        "def smoothness_const_linreg(X):\n",
        "    \"\"\"Lipschitz smoothness constant for least squares loss\"\"\"    \n",
        "    return (np.linalg.norm(X, ord=2))**2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_PUJAVOR2lMY",
        "colab": {}
      },
      "source": [
        "def PGD(w0, f, grad_f, R, prox_R, step, lmbd, n_iter=50):\n",
        "    \"\"\"Proximal gradient descent algorithm\"\"\"\n",
        "    w = w0.copy()\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    # objective history\n",
        "    objectives = []\n",
        "    # Current objective\n",
        "    obj = f(w) + R(w, lmbd)\n",
        "    objectives.append(obj)\n",
        "    for k in range(n_iter-1):\n",
        "        w = prox_R(w - step*grad_f(w), lmbd*step)\n",
        "        obj = f(w) + R(w, lmbd)\n",
        "        objectives.append(obj)\n",
        "    return w, np.array(objectives)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K6oWdYjb2lMa",
        "outputId": "f487b26f-0852-4295-c589-b334de80b2b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "L = smoothness_const_linreg(X)\n",
        "w0 = np.zeros(p)\n",
        "\n",
        "w_min_pgd, obj_min_pgd = PGD(w0=w0, f=loss_linreg, grad_f=grad_linreg, R=L1_norm, prox_R=prox_L1, step=1/L, lmbd=lambd, \n",
        "                             n_iter=50)\n",
        "print(\"Minimum : \\n\", obj_min_pgd[-1])\n",
        "print(\"Minimizers : \\n\", w_min_pgd)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum : \n",
            " 32.197691021665605\n",
            "Minimizers : \n",
            " [ 0. -0.  0. ... -0.  0.  0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kp7z04sg2lMb",
        "outputId": "2264726d-bb48-4969-c3d3-2a93e6683096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "w_min_pgd[w_min_pgd!=0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.19424436e-08, -3.64152848e-07, -4.94620228e-07, -4.16532091e-07,\n",
              "       -1.50664715e-06,  1.59761403e-06, -2.61168581e-07, -2.90057010e-07,\n",
              "       -8.76820094e-07,  2.01264058e-06, -2.33524631e-07, -1.84740675e-07,\n",
              "        2.44524799e-06, -4.97614040e-07, -4.97384095e-07, -2.01187582e-07,\n",
              "        6.31604740e-07, -8.63141841e-08, -4.88317791e-08,  1.74634594e-06,\n",
              "       -2.74371007e-07, -2.17365626e-07, -6.14739489e-07, -8.03385503e-07,\n",
              "       -6.61261751e-08,  2.21344554e-07, -4.88160241e-08, -6.33533319e-07,\n",
              "       -4.89650489e-07, -7.47049619e-07, -9.32213268e-07,  2.50824410e-07,\n",
              "       -5.70333901e-07, -7.19609546e-07, -9.04248110e-07, -9.90253680e-08,\n",
              "       -5.91914941e-07, -6.77450277e-07, -3.42160634e-07,  7.74256703e-08,\n",
              "       -9.12337326e-07, -1.01250944e-06, -1.63269573e-06, -5.41810764e-07,\n",
              "        1.34440091e-07,  1.45337268e-06,  2.60269343e-07,  1.54191562e-07,\n",
              "        6.53559942e-07,  3.33886368e-08, -6.45389119e-08, -5.47412492e-07,\n",
              "        8.64219802e-08,  1.93547182e-07,  2.68648728e-07])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VPLi-dvm2lMd"
      },
      "source": [
        "### Prox CD solver for the Lasso "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F8qs05Ep2lMd",
        "colab": {}
      },
      "source": [
        "def soft_thresh(x, u):\n",
        "    \"\"\"Soft thresholding of x at level u\"\"\"\n",
        "    return np.sign(x) * np.maximum(0., np.abs(x) - u)\n",
        "\n",
        "def cd_linreg(X, y, lamb, n_iter):\n",
        "    n_samples, n_features = X.shape\n",
        "    all_objs = np.zeros(n_iter)\n",
        "    w = np.zeros(n_features)\n",
        "    Xw = X.dot(w)\n",
        "    \n",
        "    # TODO\n",
        "    lips_const = np.linalg.norm(X, axis=0)**2\n",
        "    all_objs[0] = (1/2)*(np.linalg.norm(y - Xw, ord=2))**2 + lamb * np.linalg.norm(w, ord=1)\n",
        "    # END TODO\n",
        "    \n",
        "    for t in range(n_iter-1):\n",
        "        for j in range(n_features):\n",
        "            old_w_j = w[j]\n",
        "            # TODO\n",
        "            grad_j = np.dot(X[:,j], Xw - y)\n",
        "            step = 1/lips_const[j]\n",
        "            w[j] = soft_thresh(w[j] - step*grad_j, lamb*step)\n",
        "\n",
        "            if old_w_j != w[j]:\n",
        "                Xw += X[:,j].dot(w[j]-old_w_j)\n",
        "            #END TODO  \n",
        "        all_objs[t+1] = (1/2)*(np.linalg.norm(y - Xw, ord=2))**2 + lamb * np.linalg.norm(w, ord=1)\n",
        "    return w, all_objs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w2FWoevV2lMf",
        "outputId": "f74e7bb2-4adb-4a0b-d779-586f707b8c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "%%time\n",
        "w_min_cd_linreg, obj_min_cd_linreg = cd_linreg(X, y, lambd, 50)\n",
        "print(\"Minimum : \\n\", obj_min_cd_linreg[-1])\n",
        "print(\"Minimizers : \\n\", w_min_cd_linreg)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum : \n",
            " 26.500197757964404\n",
            "Minimizers : \n",
            " [ 0.  0.  0. ... -0.  0.  0.]\n",
            "CPU times: user 4.4 s, sys: 70.8 ms, total: 4.47 s\n",
            "Wall time: 4.91 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pej3GQnE2lMg",
        "outputId": "0c6b4b5c-02ce-4c36-fe10-13c84b742893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "w_min_cd_linreg[w_min_cd_linreg!=0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.20566814e-05, -7.94044052e-06,  2.40730833e-05,  4.44371816e-05,\n",
              "        9.65975923e-06, -1.40718946e-06, -9.16697006e-06,  1.34550857e-05])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "YYkeme0r2lMi"
      },
      "source": [
        "### Compare "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5WkSmOR12lMi",
        "outputId": "66349283-17cf-4e47-a25d-da9b1a1e83c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "y = obj_min_cd_linreg\n",
        "z = obj_min_pgd\n",
        "\n",
        "x = np.arange(1, len(y)+1)\n",
        "\n",
        "plt.plot(x, y, label='cyclic_cd')\n",
        "plt.plot(x, z, label='pgd')\n",
        "plt.yscale('log')\n",
        "plt.title(\"Comparaison des fonctions à minimiser en fonction du nombre d'itération\")\n",
        "plt.xlabel('n_iter')\n",
        "plt.ylabel('f obj')\n",
        "plt.grid()\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xYSnNB2D2lMk"
      },
      "source": [
        "## Conclusion\n",
        "On remarque donc que dans ce cas la descente de gradient par coordonnées cyclique est bien plus rapide que l'algorithme PGD. En effet, on peut constater que l'algorithme de descente par coordonnées a seulement besoin de 15 itérations pour atteindre la valeur minimale de la fonction objectif tandis que la méthode proximale décroit très rapidement sur les 5 premières itérations puis devient bien plus lente et nécessite ainsi un nombre d'itérations beaucoup plus élevé pour atteindre la valeur optimale de la fonction objectif. <br/>\n",
        "\n",
        "De plus, on a montré dans les notes de cours que la méthode de descente de gradient était plus lente que la méthode de descente par coordonnées. Les vitesses de convergences restant vraies pour les méthodes proximales, il est normal de voir la PGD plus lente que la CD. "
      ]
    }
  ]
}