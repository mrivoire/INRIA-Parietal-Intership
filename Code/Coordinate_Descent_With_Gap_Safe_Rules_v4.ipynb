{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coordinate_Descent_With_Gap_Safe_Rules_v3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnF7T4u681Yo",
        "colab_type": "text"
      },
      "source": [
        "<center> \n",
        "  <h1> Mind The Duality Gap : Safer Rules For The Lasso </h1> \n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YobSe-p3vCM7",
        "colab_type": "code",
        "outputId": "e028d1af-066f-4ea3-9ced-081b381bf932",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "!pip install python-intervals"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-intervals\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/51/b29570d4a820610be14d232aec77e6f0c66bca3d400f4903e98cc00012cb/python_intervals-1.10.0.post1-py2.py3-none-any.whl\n",
            "Installing collected packages: python-intervals\n",
            "Successfully installed python-intervals-1.10.0.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jgwRtVS95rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import linalg\n",
        "from numpy.random import multivariate_normal\n",
        "from scipy.linalg.special_matrices import toeplitz \n",
        "from numpy.random import randn\n",
        "from intervals import Interval, inf\n",
        "from scipy.optimize import minimize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGyeLaJV9bzP",
        "colab_type": "text"
      },
      "source": [
        "One chooses Coordinate Descent as iterative solver. <br/>\n",
        "The idea of coordinate descent is to decompose a large optimisation problem into\n",
        "a sequence of one-dimensional optimisation problems. \n",
        "Coordinate descent methods have become unavoidable in machine learning because\n",
        "they are very efficient for key problems, namely Lasso, Logistic Regression and\n",
        "Support Vector Machines. <br/>\n",
        "Moreover, the decomposition into small subproblems means that only a small part \n",
        "of the data is processed at each iteration and this makes coordinate descent\n",
        "easily scalable to high dimensions. \n",
        "The idea of coordinate gradient descent is to perform one iteration of gradient\n",
        "in the 1-dimensional problem :\n",
        "$$\n",
        "min_{z \\in X_{i}} f(x_{k}^{(1)}, \\ldots, x_{k}^{(l-1)}, z, x_{k}^{(l+1)}, \\ldots, x_{k}^{(n)})\n",
        "$$\n",
        "instead of solving it completely. In general it reduces drastically the cost \n",
        "of each iteration while keeping the same convergence behaviour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvLJqk-B-Bcc",
        "colab_type": "text"
      },
      "source": [
        "## Data Simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu7nS00P-Ack",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import multivariate_normal\n",
        "from scipy.linalg.special_matrices import toeplitz\n",
        "from numpy.random import randn\n",
        "\n",
        "def simu(beta, n_samples=1000, corr=0.5, for_logreg=False):\n",
        "    n_features=len(beta)\n",
        "    cov = toeplitz(corr ** np.arange(0, n_features))\n",
        "\n",
        "    # Features Matrix\n",
        "    X = multivariate_normal(np.zeros(n_features), cov, size=n_samples)\n",
        "\n",
        "    # Target labels vector with noise\n",
        "    y = X.dot(beta) + randn(n_samples)\n",
        "\n",
        "    if for_logreg:\n",
        "        y = np.sign(y)\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmxbx79ZSi2",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOQsdNTdZO4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "n_features = 100\n",
        "beta = np.random.randn(n_features)\n",
        "\n",
        "X, y = simu(beta, n_samples=1000, corr=0.5, for_logreg=False)\n",
        "\n",
        "# print(\"Features matrix X : \\n\", X)\n",
        "# print(\"Target vector y : \\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8xEb5zt-PjM",
        "colab_type": "text"
      },
      "source": [
        "## Coordinate Descent Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5QYv5157fCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cyclic_coordinate_descent(X, y, n_iter=10):\n",
        "    \"\"\"Solver : cyclic coordinate descent \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    X: numpy.ndarray, shape (n_samples, n_features)\n",
        "       features matrix\n",
        "\n",
        "    y: numpy.array, shape (n_samples, )\n",
        "       target labels vector\n",
        "\n",
        "    n_iter: int, default = 10\n",
        "            number of iterations  \n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    beta: numpy.array, shape(n_features,)\n",
        "          parameters vector\n",
        "\n",
        "    all_objs: numpy.array, shape(n_features)\n",
        "              residuals vector\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialisation of the parameters\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "    all_objs = []\n",
        "\n",
        "    beta = np.zeros(n_features)\n",
        "    residuals = y - X.dot(beta)\n",
        "\n",
        "    # Computation of the lipschitz constants vector \n",
        "\n",
        "    lips_const = np.linalg.norm(X, axis=0)**2\n",
        "\n",
        "    # Iterations of the algorithm\n",
        "    for k in range(n_iter):\n",
        "\n",
        "        # One cyclicly updates the i^{th} coordinate corresponding to the rest \n",
        "        # in the Euclidean division by the number of features \n",
        "        # This allows to always selecting an index between 1 and n_features\n",
        "        i = k % n_features + 1\n",
        "\n",
        "        old_beta_i = beta[i].copy()\n",
        "        step = 1/lips_const[i] \n",
        "        reg = old_beta_i * X[:,i]\n",
        "        grad = (X[:,i].T).dot(residuals + reg)\n",
        "\n",
        "        # Update of the parameters\n",
        "        beta[i] += step*grad \n",
        "\n",
        "        # Update of the residuals\n",
        "        residuals += np.dot(X[:,i], old_beta_i - beta[i])\n",
        "\n",
        "        if k % n_features == 0:\n",
        "            # If k % n_features == 0 then we have updated all the coordinates\n",
        "            # This means that we have performed a whole cycle \n",
        "            # One computes the objective function \n",
        "            all_objs.append((residuals**2).sum()/2.)\n",
        "\n",
        "    return beta, np.array(all_objs)       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxUFSVWLi9Iv",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ByKXUihi8zq",
        "colab_type": "code",
        "outputId": "4d91fb2f-7d01-4936-e420-f01005f1bc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "beta_hat_cyclic_cd, objs_cyclic_cd = cyclic_coordinate_descent(X, y, n_iter=10)\n",
        "\n",
        "# print(\"Beta hat cyclic coordinate descent : \\n\", beta_hat_cyclic_cd)\n",
        "# print(\"Objective function for the optimum parameters vector beta hat coordinate descent : \\n\", objs_cyclic_cd)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.91 ms, sys: 1.66 ms, total: 3.57 ms\n",
            "Wall time: 4.19 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knHNGoeflbKv",
        "colab_type": "code",
        "outputId": "5304d7b5-50a8-44df-8c6f-16d859c7769d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "%%time\n",
        "beta_hat_ols, objs_ols,_,_ = np.linalg.lstsq(X, y)\n",
        "\n",
        "# print(\"Beta hat OLS : \\n\", beta_hat_ols)\n",
        "# print(\"Objective function for the optimum parameters vector beta hat ols ! \\n\", objs_ols)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 9.63 ms, sys: 9.28 ms, total: 18.9 ms\n",
            "Wall time: 21.7 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r83VzHFmQsf",
        "colab_type": "text"
      },
      "source": [
        "**Results** <br/>\n",
        "\n",
        "We can observe that the cyclic coordinate descent is much more efficient than the ordinary least square solver, especially regarding its time computation. <br/>\n",
        "This phenomenon can be explained by the fact that the coordinate cyclic descent is based onto an update of the parameters vector coordinate by coordinate whereas the ordinary least squares relies on an update of all the coordinates of the parameters vector at each iteration what is very expensive. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPOVCeXaF7dP",
        "colab_type": "text"
      },
      "source": [
        "## Coordinate Descent With Gap Safe Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipzuV7dKdZ0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 11\n",
        "def compute_theta_k(X, y, beta_k, lmbda):\n",
        "  \"\"\"Iterative computation of the dual optimal solution theta\n",
        "     Dynamic Safe Rules\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  X: numpy.ndarray, shape = (n_samples, n_features)\n",
        "     features matrix\n",
        "\n",
        "  y: numpy.array, shape = (n_features, )\n",
        "     target labels vector\n",
        "\n",
        "  lmbda: numpy.array, shape = (n_iter, )\n",
        "         regularization parameters vector\n",
        "\n",
        "  beta_k: numpy.array, shape = (n_features, )\n",
        "          primal optimal parameters vector\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  theta_k: float \n",
        "           dual optimal parameters vector\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialization of the parameters \n",
        "      # Residuals vector \n",
        "  rho_k = y - np.dot(X, beta_k)\n",
        "      # Proportionality constant \n",
        "  a_k = np.dot(y.T, rho_k)/(lmbda*np.linalg.norm(rho_k)**2)\n",
        "  b_k = -1/np.linalg.norm(np.dot(X.T, rho_k), np.inf)\n",
        "  c_k = 1/np.linalg.norm(np.dot(X.T, rho_k), np.inf)\n",
        "\n",
        "  alpha_k = min(max(a_k, b_k), c_k)\n",
        "      # Dual optimal parameters vector\n",
        "  theta_k = alpha_k * rho_k\n",
        "\n",
        "  return theta_k\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKlWwrVBLNoC",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T82M1q6-LNQw",
        "colab_type": "code",
        "outputId": "ceb49c18-08ad-4bbf-d5f9-5cc36f5257fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "lmbda = 0.1\n",
        "theta_k = compute_theta_k(X, y, beta_k=beta, lmbda=lmbda)\n",
        "\n",
        "# print(\"Dual optimal paramters vector at iteration k theta_k : \\n\", theta_k)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.49 ms, sys: 1.23 ms, total: 2.72 ms\n",
            "Wall time: 2.35 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtyctULMpAi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def radius_eq20(beta, theta, lmbda_t, lmbda_t_1, r_lmbda_t_1):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  beta: numpy.array, shape = (n_features, )\n",
        "        primal optimal parameters vector\n",
        "\n",
        "  theta: numpy.array, shape = (n_features, )\n",
        "         dual optimal parameters vector\n",
        "\n",
        "  lmbda_t: float\n",
        "           regularization parameter at iteration t\n",
        "\n",
        "  lmbda_t_1: float\n",
        "             regularization parameter at iteration t-1\n",
        "  \n",
        "  r_lmbda_t_1: float\n",
        "               radius related to the regularization parameter lmbda_t_1\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  r_lmbda_t: float\n",
        "             radius related to the regularization parameter lmbda_t \n",
        "  \"\"\"\n",
        "\n",
        "  r_square_lmbda_t = (lmbda_t_1/lmbda_t)*r_lmbda_t_1**2 + (1 - lmbda_t/lmbda_t_1)*np.linalg.norm((X @ beta - y)/lmbda_t)**2 - (lmbda_t_1/lmbda_t - 1)*np.linalg.norm(theta)**2\n",
        "  r_lmbda_t = np.sqrt(r_square_lmbda_t)\n",
        "\n",
        "  return r_lmbda_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keF9Mj6LyTTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def R_primal(X, y, beta, lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  \n",
        "  X: numpy.ndarray, shape=(n_samples, n_features)\n",
        "     features matrix\n",
        "\n",
        "  y: numpy.array, shape=(n_samples, )\n",
        "     target labels vector \n",
        "\n",
        "  beta: numpy.array, shape=(n_features, )\n",
        "        primal optimal parameters vector\n",
        "\n",
        "  lmbda: float\n",
        "         regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  R_hat_lmbda: float\n",
        "               primal radius of the dome\n",
        "  \"\"\"\n",
        "\n",
        "  R_hat_lmbda = (1/lmbda)*np.max(np.linalg.norm(y)**2 - np.linalg.norm(np.dot(X, beta) - y)**2 - 2*lmbda*np.linalg.norm(beta, 1), 0)**(1/2)\n",
        "\n",
        "  return R_hat_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GL46v0ncTII",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJGmXOnmcVX6",
        "colab_type": "code",
        "outputId": "58366333-c7c1-4d3d-9a9c-291ba2748216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "R_hat_lmbda = R_primal(X, y, beta, lmbda)\n",
        "\n",
        "print(\"R primal (R_hat_lmbda) : \\n\", R_hat_lmbda)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R primal (R_hat_lmbda) : \n",
            " 3464.8358952601366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zci0OfYHzsNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def R_dual(y, theta, lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  \n",
        "  y: numpy.array, shape=(n_samples, ) \n",
        "     target labels vector \n",
        "\n",
        "  theta: numpy.array, shape=(n_features, )\n",
        "        dual optimal parameters vector\n",
        "\n",
        "  lmbda: float\n",
        "         regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  R_inv_hat_lmbda: float\n",
        "                   dual radius of the dome\n",
        "  \"\"\"\n",
        "\n",
        "  R_inv_hat_lmbda = np.linalg.norm(theta - y/lmbda)\n",
        "\n",
        "  return R_inv_hat_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceac9P_ecsNc",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGACeMlHcuEm",
        "colab_type": "code",
        "outputId": "da30d37a-2ce2-45c0-840d-7b3a6630f052",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "R_inv_hat_lmbda = R_dual(y, theta_k, lmbda)\n",
        "\n",
        "print(\"R dual (R_inv_hat_lmbda) : \\n\", R_inv_hat_lmbda)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R dual (R_inv_hat_lmbda) : \n",
            " 3479.259836114735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9quLJwEi4ve4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Closed form \n",
        "def radius_thm2(R_hat_lmbda, R_inv_hat_lmbda):\n",
        "  \"\"\"Compute the radius of the safe sphere region\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  R_hat_lmbda: float \n",
        "               primal radius of the safe dome region\n",
        "\n",
        "  R_inv_hat_lmbda: float\n",
        "                   dual radius of the safe dome region\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  r_lmbda: float\n",
        "           radius of the safe sphere region\n",
        "  \"\"\"\n",
        "\n",
        "  r_lmbda = np.sqrt(R_inv_hat_lmbda**2 - R_hat_lmbda**2)\n",
        "\n",
        "  return r_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P50lvXov55f4",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abAoO_1w56-T",
        "colab_type": "code",
        "outputId": "4925da80-ba4e-4f0a-9f91-af5e216160cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "r_lmbda = radius_thm2(R_hat_lmbda, R_inv_hat_lmbda)\n",
        "\n",
        "print(\"Radius of the safe sphere region r_lmbda : \\n\", r_lmbda)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Radius of the safe sphere region r_lmbda : \n",
            " 316.4825842254526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUoc5wkKxWoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 19 : Gap Safe Dome\n",
        "def gap_safe_dome(y, lmbda, theta_k, beta_k, R_hat_lmbda, R_inv_hat_lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ---------\n",
        "\n",
        "  y: np.array, shape = (n_samples, )\n",
        "\n",
        "  lmbda: float \n",
        "         regularization parameter\n",
        "  \n",
        "  theta_k: np.array, shape = (n_features, )\n",
        "           dual optimal parameters vector\n",
        "\n",
        "  beta_k: np.array, shape = (n_features, )\n",
        "          primal optimal parameters vector\n",
        "  \n",
        "  R_hat_lmbda: float\n",
        "               primal radius of the dome\n",
        "\n",
        "  R_inv_hat_lmbda: float\n",
        "                   dual radius of the dome\n",
        "  \n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  C_k: interval\n",
        "       gape safe dome\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  c_k = ((y/lmbda) + theta_k)/2\n",
        "  r_k = R_inv_hat_lmbda/2\n",
        "  sphere_k = interval[c_k - r_k, c_k + r_k]\n",
        "\n",
        "  alpha_k = 2*(R_hat_lmbda/R_inv_hat_lmbda)**2 - 1\n",
        "  w_k = (theta_k - y/lmbda)/np.linalg.norm(theta_k - y/lmbda)\n",
        "\n",
        "  margin_k = - alpha_k*r_k*w_k\n",
        "\n",
        "  # c_k - alpah_k*r_k*w_k is the projection of the ball center c on the hyperplane\n",
        "  # c = ball center\n",
        "  # r = ball radius\n",
        "  # oriented hyperplane with unit normal vector w and parameter alpha \n",
        "  # such that c - alpha*r*w is the projection of c on the hyperplane\n",
        "\n",
        "  C_k = sphere_k.intersection(margin_k) # problème d'intersection avec l'hyperplane\n",
        "\n",
        "  return C_k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQc8HFRW8ZHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigma_support_function(x_j, theta):\n",
        "  \"\"\"Support Function\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  x_j: np.array, shape = (n_samples, )\n",
        "       vector of samples for a given feature j\n",
        "\n",
        "  theta: np.array, shape = (n_samples, )\n",
        "         vector of parameters \n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  sigma: float\n",
        "         scalar product <x, theta> between the j^th feature X[:,j] \n",
        "         and the vector of parameters theta\n",
        "  \"\"\"\n",
        "  sigma = -np.dot(x_j.T, theta)\n",
        "  \n",
        "  return sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHrikFTdBdWX",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ-_rIFXBVjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_1 = X[:,1]\n",
        "theta = np.random.randn(x_1.shape[0])\n",
        "sigma = sigma_support_function(x_1, theta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXfEeCqs-pa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One does not use this form for the support function which is not closed\n",
        "def sigma_C(x_j, theta):\n",
        "  \"\"\"Support Function\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  x_j: np.array, shape = (n_samples, )\n",
        "       vector of samples for a given feature j  \n",
        "\n",
        "  theta: np.array, shape = (n_samples, )\n",
        "         vector of parameters\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  support_function: float\n",
        "                    maximum value of the scalar product between\n",
        "                    the j^th feature X[:,j] and the vector of parameters theta\n",
        "                    over the convex set C \n",
        "  \"\"\"\n",
        "  support_function = minimize(sigma_support_function, x_j, theta, method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
        "  support_function = -support_function\n",
        "  return support_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o6PTwgS8GSI",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XAmMs8l8Ii4",
        "colab_type": "code",
        "outputId": "ec77766c-b821-424b-f78a-02728437a288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "x_1 = X[:,1]\n",
        "theta = np.random.randn(x_1.shape[0])\n",
        "sigma = sigma_support_function(x_1, theta)\n",
        "# support_function = sigma_C(x_1, theta)\n",
        "print(sigma)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-21.800880808362834\n",
            "CPU times: user 400 µs, sys: 24 µs, total: 424 µs\n",
            "Wall time: 270 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRzJdP1e9lbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One does not use this form of the function mu since it depends on a non closed form of the support function\n",
        "def mu_C(x_j, theta):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  x_j: np.array, shape = (n_samples, )\n",
        "       feature x_j \n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  mu: float \n",
        "      maximum between two sigma_C(x_j) and sigma_C(-x_j)\n",
        "  \"\"\"\n",
        "\n",
        "  # mu = max(sigma_C(x_j, theta), sigma_C(-x_j, theta))\n",
        "  mu = max(sigma_support_function(x_j, theta), sigma_support_function(-x_j, theta))\n",
        "\n",
        "  return mu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GNuV2EkEPno",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSfY3Bd0ERvC",
        "colab_type": "code",
        "outputId": "c07ded3f-9b43-49ea-f875-4da2d32218ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "mu = mu_C(x_1, theta)\n",
        "\n",
        "print(\"mu C : \\n\", mu) # Problème d'optimiseur "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mu C : \n",
            " 21.800880808362837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjD5o6m5QRqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# One directly the form of the function mu applied to the sphere of center c and radius r since it is closed\n",
        "def mu_B(x_j, c, r):\n",
        "  \"\"\"Function mu applied to the sphere of center c and radius r \n",
        "     for the j^th feature X[:,j]\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  x_j: numpy.array, shape=(n_samples, )\n",
        "       j^th feature X[:,j]\n",
        "\n",
        "  c: float\n",
        "     center of the sphere\n",
        "     \n",
        "  r: float\n",
        "     radius of the sphere\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  mu: float\n",
        "      maximum value between the scalar products of theta and x_j\n",
        "      and theta and -x_j\n",
        "  \"\"\"\n",
        "\n",
        "  mu = abs(np.dot(x_j.T, c)) + r*np.linalg.norm(x_j)\n",
        "\n",
        "  return mu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcbTSpbjR-wU",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3RWh_CZSDEO",
        "colab_type": "code",
        "outputId": "c5150ed2-d089-4bf5-fc8a-abe75d7e8507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x_1 = X[:,1]\n",
        "c = np.random.randn(x_1.shape[0])\n",
        "r = 1\n",
        "mu = mu_B(x_1, c, r)\n",
        "\n",
        "print(\"mu value : \\n\", mu)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mu value : \n",
            " 34.11552024588202\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph4uQljp7d19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 7 : Active Set\n",
        "def active_set_vs_zero_set(X, c, r):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  X: numpy.ndarray, shape = (n_samples, n_features)\n",
        "     features matrix \n",
        "\n",
        "  c: numpy.array, shape = (n_samples, )\n",
        "     center of the safe sphere\n",
        "\n",
        "  r: float \n",
        "     radius of the safe sphere\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  A_C: numpy.array, shape = (n_idx_active_features, )\n",
        "       active set : contains the indices of the relevant features\n",
        "  \n",
        "  Z_C: numpy.array, shape = (n_idx_zero_features, )\n",
        "       zero set : contains the indices of the irrelevant features\n",
        "  \"\"\"\n",
        "  A_C = []\n",
        "  Z_C = []\n",
        "  p = X.shape[1]\n",
        "  for j in range(p):\n",
        "    x_j = X[:,j]\n",
        "    mu = mu_B(x_j, c, r)\n",
        "    if mu >= 1:\n",
        "      A_C.append(j)\n",
        "    else:\n",
        "      Z_C.append(j)\n",
        "\n",
        "  return A_C, Z_C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzMzi0DYLwgw",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez_W8H7ALx9a",
        "colab_type": "code",
        "outputId": "14c09a46-41e3-437d-9e1f-46b8c59becc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "c = theta_hat \n",
        "r = 0.000001\n",
        "A_C, Z_C = active_set_vs_zero_set(X, c, r)\n",
        "\n",
        "print(\"Active Set : \\n\", A_C)\n",
        "print(\"Zero Set : \\n\", Z_C)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Active Set : \n",
            " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Zero Set : \n",
            " [10, 35, 69, 81]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2c2W7mbi-pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sign(x):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  x: float\n",
        "     \n",
        "  Returns\n",
        "  -------\n",
        "  s: sign int\n",
        "     (-1) if x < 0,, (+1) if x > 0, 0 if x = 0\n",
        "  \"\"\"\n",
        "\n",
        "  if x > 0:\n",
        "    s = 1\n",
        "  elif x < 0:\n",
        "    s = -1\n",
        "  else:\n",
        "    s = 0\n",
        "\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtdBNZvFPUSD",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Tq4TH_PWbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 2\n",
        "s = sign(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry19OgPy9qJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def soft_thresholding(u,x):\n",
        "  \"\"\"\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  u: float\n",
        "     threshold\n",
        "\n",
        "  x: float\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ST: float\n",
        "      0 between -u and +u or slope of the straight line x - u otherwise \n",
        "      \n",
        "  \"\"\"\n",
        "\n",
        "  ST = sign(x)*np.max(np.abs(x) - u, 0)\n",
        "\n",
        "\n",
        "  return ST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRPtCqAiPdM_",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azbXVoHKPc7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u = 1\n",
        "ST = soft_thresholding(u,x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFdRVITul7go",
        "colab_type": "text"
      },
      "source": [
        "## Maximization of the dual problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO9QNioTmASW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dual_solver(X, y, beta_hat, lmbda):\n",
        "  \"\"\"Maximization of the dual problem \n",
        "     Orthogonal projection of the center of the safe sphere\n",
        "     onto the feasible set \n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  X: numpy.ndarray, shape = (n_samples, n_features)\n",
        "     features matrix\n",
        "\n",
        "  y: numpy.array, shape = (n_samples, )\n",
        "     target labels vector\n",
        "\n",
        "  beta_hat: numpy.array shape = (n_features, )\n",
        "            current primal optimal parameters vector \n",
        "\n",
        "  lmbda: float\n",
        "         regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  theta_hat: numpy.array, shape = (n_samples, )\n",
        "             dual optimal parameters vector\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Link equation : Equation 2\n",
        "  residus = (y - np.dot(X, beta_hat))/lmbda\n",
        "\n",
        "  # Orthogonal projection of theta_hat onto the feasible set \n",
        "  theta_hat = residus / max(np.max(np.abs(residus)), 1)\n",
        "\n",
        "  # Objective function \n",
        "  # obj = (1/2)*np.linalg.norm(y, 2)**2 - ((lmbda**2)/2)*np.linalg.norm(theta_hat - y/lmbda, 2)**2\n",
        "\n",
        "  return theta_hat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS7GanohEs0m",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjNMewcvEuFJ",
        "colab_type": "code",
        "outputId": "16af0627-fe2d-4b3b-a399-d2d194e8e800",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%%time\n",
        "theta_hat = dual_solver(X, y, beta_hat_cyclic_cd, lmbda)\n",
        "# print(\"Dual optimal parameters vector theta_hat : \\n\", theta_hat)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.61 ms, sys: 0 ns, total: 1.61 ms\n",
            "Wall time: 998 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BR6sztHBJAKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 1 : Primal Problem \n",
        "def primal_pb(X, y, beta, lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  X: numpy.ndarray, shape = (n_samples, n_features)\n",
        "     features matrix\n",
        "\n",
        "  y: numpy.array, shape = (n_samples, )\n",
        "     target labels vector\n",
        "\n",
        "  beta: numpy.array, shape = (n_features, )\n",
        "        initial vector of primal parameters\n",
        "\n",
        "  lmbda: float\n",
        "         regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  P_lmbda: float\n",
        "           value of the primal problem for a given beta vector\n",
        "  \"\"\"\n",
        "\n",
        "  P_lmbda = (1/2)*np.linalg.norm(np.dot(X, beta) - y, 2)**2 + lmbda*np.linalg.norm(beta, 1)\n",
        "\n",
        "  return P_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAQCM4FzJgZN",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnY6_NM7JiPJ",
        "colab_type": "code",
        "outputId": "9c3b51c0-e5ae-4bb5-e24a-bba8b3c7416d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%%time\n",
        "P_lmbda = primal_pb(X, y, beta_hat_cyclic_cd, lmbda)\n",
        "\n",
        "print(\"Value of the primal problem at the optimum : \\n\", P_lmbda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value of the primal problem at the optimum : \n",
            " 49634.74389785626\n",
            "CPU times: user 3.17 ms, sys: 2.73 ms, total: 5.9 ms\n",
            "Wall time: 8.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp5TNH_oJE5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 2\n",
        "def dual_pb(y, theta, lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  y: numpy.array, shape = (n_features, )\n",
        "\n",
        "  theta: numpy.array, shape = (n_samples, )\n",
        "         initial vector of dual parameters\n",
        "\n",
        "  lmbda: float\n",
        "         regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  D_lmbda: float\n",
        "           value of the dual problem for a given theta vector\n",
        "  \"\"\"\n",
        "\n",
        "  D_lmbda = (1/2)*np.linalg.norm(y, ord=2)**2 - ((lmbda**2)/2)*np.linalg.norm(theta - y/lmbda, ord=2)**2\n",
        "  \n",
        "  return D_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D0iOzndKDUK",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lGkI0w0KEqf",
        "colab_type": "code",
        "outputId": "1face7af-a2c3-4155-c00c-7485e1e0ecff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%%time\n",
        "D_lmbda = dual_pb(y, theta_hat, lmbda)\n",
        "print(\"Value of the dual problem at the optimum : \\n\", D_lmbda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Value of the dual problem at the optimum : \n",
            " 260.55952395331406\n",
            "CPU times: user 241 µs, sys: 150 µs, total: 391 µs\n",
            "Wall time: 321 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0CMBVOPmuO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def duality_gap(P_lmbda, D_lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  P_lmbda: float\n",
        "           value of the primal problem at the optimum beta_hat\n",
        "\n",
        "  D_lmbda: float\n",
        "           value of the dual problem at the optimum theta_hat\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  G_lmbda: float\n",
        "           duality gap between the primal optimal and the dual optimal\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Duality gap \n",
        "  # If it is equal to 0 then the primal optimal is equal to the dual optimal \n",
        "  # and the strong duality holds\n",
        "  # If there exists a gap between the primal optimal and the dual optimal\n",
        "  # then one only has the weak duality with P_lmbda >= D_lmbda\n",
        "  G_lmbda = P_lmbda - D_lmbda\n",
        "\n",
        "  return G_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxsJEAyqX9VL",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdwNXhoxX-tN",
        "colab_type": "code",
        "outputId": "77a97403-e63e-46b0-829a-3bb20c80cd80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "%%time \n",
        "G_lmbda = duality_gap(P_lmbda, D_lmbda)\n",
        "\n",
        "print(\"Duality gap at the optimum : \\n\", G_lmbda)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Duality gap at the optimum : \n",
            " 49374.18437390294\n",
            "CPU times: user 248 µs, sys: 0 ns, total: 248 µs\n",
            "Wall time: 198 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrk8Ww_GhJgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 18 : Gap Safe Sphere\n",
        "import pandas as pd\n",
        "def gap_safe_sphere(c, r):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  c: numpy.array, shape = (n_samples,)\n",
        "     center of the sphere\n",
        "  \n",
        "  r: float\n",
        "     radius of the sphere\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  C_k: interval\n",
        "       sphere of center c and of radius r\n",
        "  \"\"\"\n",
        "\n",
        "  C_k = np.linalg.norm(np.subtract(np.indices(r).T, np.asarray(c)), axis=2)\n",
        "  return C_k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZW_3nAo1hK93",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG1gXczLhMb7",
        "colab_type": "code",
        "outputId": "422204a3-9d71-4612-e8db-6f0a6e48547c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "r = np.ones(theta_hat.shape[0])\n",
        "c = theta_hat\n",
        "# gap_safe_sphere(c, r)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-e781ede3a69c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# gap_safe_sphere(c, r)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mindices\u001b[0;34m(dimensions, dtype, sparse)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1713\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         idx = arange(dim, dtype=dtype).reshape(\n",
            "\u001b[0;31mValueError\u001b[0m: maximum supported dimension for an ndarray is 32, found 1001"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq3JkhBXFvKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cd_with_gap_safe_rules(X, y, epsilon, K, f, lmbda, T, lmbda_max):\n",
        "  \"\"\"Coordinate descent with gap safe rules \n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  X: numpy.ndarray, shape = (n_samples, n_features)\n",
        "     features matrix\n",
        "\n",
        "  y: numpy.array, shape = (n_features, )\n",
        "     target labels vector\n",
        "\n",
        "  epsilon: float \n",
        "           accuracy\n",
        "\n",
        "  T: int\n",
        "     number of epochs\n",
        "\n",
        "  K: int\n",
        "     number of iterations\n",
        "\n",
        "  f: int\n",
        "     frequency\n",
        "\n",
        "  lmbda: numpy.array, shape = (T-1, )\n",
        "         regularization parameters vector\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  beta_lmbda: numpy.array, shape = (n_features, )\n",
        "              primal optimal parameters vector \n",
        "              for the regularization parameter lmbda_t for t from 1 to T-1\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialization \n",
        "  lmbda = []\n",
        "  lmbda[0] = lmbda_max\n",
        "  beta = dict()\n",
        "  beta[\"lmbda0\"] = 0\n",
        "\n",
        "  for t in range(T-1):\n",
        "    beta = beta[\"lambda\" & (t-1)]\n",
        "\n",
        "    for k in range(K):\n",
        "      if k % f == 1:\n",
        "\n",
        "        # Computation of theta \n",
        "        # Equation 11\n",
        "        theta_k = compute_theta_k(X, y, beta, lmbda)\n",
        "        # Equation 18 : Safe Sphere\n",
        "        \n",
        "        # Equation Active Set Theorem 1\n",
        "        A_C, Z_C = active_set_vs_zero_set(X)\n",
        "\n",
        "      \n",
        "        if G_lmbda(beta, theta) <= epsilon:\n",
        "          beta_lmbda = beta\n",
        "          break\n",
        "\n",
        "        for j in A_C:\n",
        "          beta_j = soft_thresholding(lmbda_t/np.linalg.norm(X[:,j])**2, beta_j - ((X[:,j].T @ (X @ beta - y))/np.linalg.norm(X[:,j])**2)\n",
        "\n",
        "  return beta_lmbda_t"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}