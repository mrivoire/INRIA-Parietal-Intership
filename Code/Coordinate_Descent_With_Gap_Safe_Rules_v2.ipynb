{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coordinate_Descent_With_Gap_Safe_Rules_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnF7T4u681Yo",
        "colab_type": "text"
      },
      "source": [
        "<center> \n",
        "  <h1> Mind The Duality Gap : Safer Rules For The Lasso </h1> \n",
        "</center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YobSe-p3vCM7",
        "colab_type": "code",
        "outputId": "d713c50c-2cfc-4185-ec3e-1f40e49a05b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!pip install python-intervals"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-intervals\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/51/b29570d4a820610be14d232aec77e6f0c66bca3d400f4903e98cc00012cb/python_intervals-1.10.0.post1-py2.py3-none-any.whl\n",
            "Installing collected packages: python-intervals\n",
            "Successfully installed python-intervals-1.10.0.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jgwRtVS95rB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import linalg\n",
        "from numpy.random import multivariate_normal\n",
        "from scipy.linalg.special_matrices import toeplitz \n",
        "from numpy.random import randn\n",
        "from intervals import Interval, inf\n",
        "from scipy.optimize import minimize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGyeLaJV9bzP",
        "colab_type": "text"
      },
      "source": [
        "One chooses Coordinate Descent as iterative solver. <br/>\n",
        "The idea of coordinate descent is to decompose a large optimisation problem into\n",
        "a sequence of one-dimensional optimisation problems. \n",
        "Coordinate descent methods have become unavoidable in machine learning because\n",
        "they are very efficient for key problems, namely Lasso, Logistic Regression and\n",
        "Support Vector Machines. <br/>\n",
        "Moreover, the decomposition into small subproblems means that only a small part \n",
        "of the data is processed at each iteration and this makes coordinate descent\n",
        "easily scalable to high dimensions. \n",
        "The idea of coordinate gradient descent is to perform one iteration of gradient\n",
        "in the 1-dimensional problem :\n",
        "$$\n",
        "min_{z \\in X_{i}} f(x_{k}^{(1)}, \\ldots, x_{k}^{(l-1)}, z, x_{k}^{(l+1)}, \\ldots, x_{k}^{(n)})\n",
        "$$\n",
        "instead of solving it completely. In general it reduces drastically the cost \n",
        "of each iteration while keeping the same convergence behaviour."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvLJqk-B-Bcc",
        "colab_type": "text"
      },
      "source": [
        "## Data Simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu7nS00P-Ack",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import multivariate_normal\n",
        "from scipy.linalg.special_matrices import toeplitz\n",
        "from numpy.random import randn\n",
        "\n",
        "def simu(beta, n_samples=1000, corr=0.5, for_logreg=False):\n",
        "    n_features=len(beta)\n",
        "    cov = toeplitz(corr ** np.arange(0, n_features))\n",
        "\n",
        "    # Features Matrix\n",
        "    X = multivariate_normal(np.zeros(n_features), cov, size=n_samples)\n",
        "\n",
        "    # Target labels vector with noise\n",
        "    y = X.dot(beta) + randn(n_samples)\n",
        "\n",
        "    if for_logreg:\n",
        "        y = np.sign(y)\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qmxbx79ZSi2",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOQsdNTdZO4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(0)\n",
        "n_features = 100\n",
        "beta = np.random.randn(n_features)\n",
        "\n",
        "X, y = simu(beta, n_samples=1000, corr=0.5, for_logreg=False)\n",
        "\n",
        "# print(\"Features matrix X : \\n\", X)\n",
        "# print(\"Target vector y : \\n\", y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8xEb5zt-PjM",
        "colab_type": "text"
      },
      "source": [
        "## Coordinate Descent Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5QYv5157fCh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cyclic_coordinate_descent(X, y, n_iter=10):\n",
        "    \"\"\"Solver : cyclic coordinate descent \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    X: numpy.ndarray, shape (n_samples, n_features)\n",
        "       features matrix\n",
        "\n",
        "    y: numpy.array, shape (n_samples, )\n",
        "       target labels vector\n",
        "\n",
        "    n_iter: int, default = 10\n",
        "            number of iterations  \n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    beta: numpy.array, shape(n_features,)\n",
        "          parameters vector\n",
        "\n",
        "    all_objs: numpy.array, shape(n_features)\n",
        "              residuals vector\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialisation of the parameters\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "    all_objs = []\n",
        "\n",
        "    beta = np.zeros(n_features)\n",
        "    residuals = y - X.dot(beta)\n",
        "\n",
        "    # Computation of the lipschitz constants vector \n",
        "\n",
        "    lips_const = np.linalg.norm(X, axis=0)**2\n",
        "\n",
        "    # Iterations of the algorithm\n",
        "    for k in range(n_iter):\n",
        "\n",
        "        # One cyclicly updates the i^{th} coordinate corresponding to the rest \n",
        "        # in the Euclidean division by the number of features \n",
        "        # This allows to always selecting an index between 1 and n_features\n",
        "        i = k % n_features + 1\n",
        "\n",
        "        old_beta_i = beta[i].copy()\n",
        "        step = 1/lips_const[i] \n",
        "        reg = old_beta_i * X[:,i]\n",
        "        grad = (X[:,i].T).dot(residuals + reg)\n",
        "\n",
        "        # Update of the parameters\n",
        "        beta[i] += step*grad \n",
        "\n",
        "        # Update of the residuals\n",
        "        residuals += np.dot(X[:,i], old_beta_i - beta[i])\n",
        "\n",
        "        if k % n_features == 0:\n",
        "            # If k % n_features == 0 then we have updated all the coordinates\n",
        "            # This means that we have performed a whole cycle \n",
        "            # One computes the objective function \n",
        "            all_objs.append((residuals**2).sum()/2.)\n",
        "\n",
        "    return beta, np.array(all_objs)       \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxUFSVWLi9Iv",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ByKXUihi8zq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "25e61837-4b93-481b-d13a-32070b4c3543"
      },
      "source": [
        "%%time\n",
        "beta_hat_cyclic_cd, objs_cyclic_cd = cyclic_coordinate_descent(X, y, n_iter=10)\n",
        "\n",
        "# print(\"Beta hat cyclic coordinate descent : \\n\", beta_hat_cyclic_cd)\n",
        "# print(\"Objective function for the optimum parameters vector beta hat coordinate descent : \\n\", objs_cyclic_cd)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.29 ms, sys: 80 Âµs, total: 2.37 ms\n",
            "Wall time: 1.94 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knHNGoeflbKv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "f7a91d7a-84ce-49c2-c733-16ea937d8a5a"
      },
      "source": [
        "%%time\n",
        "beta_hat_ols, objs_ols,_,_ = np.linalg.lstsq(X, y)\n",
        "\n",
        "# print(\"Beta hat OLS : \\n\", beta_hat_ols)\n",
        "# print(\"Objective function for the optimum parameters vector beta hat ols ! \\n\", objs_ols)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.1 ms, sys: 12 ms, total: 24.1 ms\n",
            "Wall time: 21.3 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4r83VzHFmQsf",
        "colab_type": "text"
      },
      "source": [
        "**Results** <br/>\n",
        "\n",
        "We can observe that the cyclic coordinate descent is much more efficient than the ordinary least square solver, especially regarding its time computation. <br/>\n",
        "This phenomenon can be explained by the fact that the coordinate cyclic descent is based onto an update of the parameters vector coordinate by coordinate whereas the ordinary least squares relies on an update of all the coordinates of the parameters vector at each iteration what is very expensive. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPOVCeXaF7dP",
        "colab_type": "text"
      },
      "source": [
        "## Coordinate Descent With Gap Safe Rules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipzuV7dKdZ0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 11\n",
        "def compute_theta_k(X, y, beta_k, lmbda):\n",
        "  \"\"\"Iterative computation of the dual optimal solution theta\n",
        "     Dynamic Safe Rules\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  X: numpy.ndarray, shape = (n_samples, n_features)\n",
        "     features matrix\n",
        "\n",
        "  y: numpy.array, shape = (n_features, )\n",
        "     target labels vector\n",
        "\n",
        "  lmbda: numpy.array, shape = (n_iter, )\n",
        "         regularization parameters vector\n",
        "\n",
        "  beta_k: numpy.array, shape = (n_features, )\n",
        "          primal optimal parameters vector\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  theta_k: float \n",
        "           dual optimal parameters vector\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialization of the parameters \n",
        "      # Residuals vector \n",
        "  rho_k = y - np.dot(X, beta_k)\n",
        "      # Proportionality constant \n",
        "  a_k = np.dot(y.T, rho_k)/(lmbda*np.linalg.norm(rho_k)**2)\n",
        "  b_k = -1/np.linalg.norm(np.dot(X.T, rho_k), np.inf)\n",
        "  c_k = 1/np.linalg.norm(np.dot(X.T, rho_k), np.inf)\n",
        "\n",
        "  alpha_k = min(max(a_k, b_k), c_k)\n",
        "      # Dual optimal parameters vector\n",
        "  theta_k = alpha_k * rho_k\n",
        "\n",
        "  return theta_k\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKlWwrVBLNoC",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T82M1q6-LNQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "1a136e70-574c-47c1-9e3c-f90a76fee79a"
      },
      "source": [
        "%%time\n",
        "lmbda = 0.1\n",
        "theta_k = compute_theta_k(X, y, beta_k=beta, lmbda=lmbda)\n",
        "\n",
        "# print(\"Dual optimal paramters vector at iteration k theta_k : \\n\", theta_k)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.22 ms, sys: 1.61 ms, total: 3.83 ms\n",
            "Wall time: 3.97 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtyctULMpAi1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def radius_eq20(beta, theta, lmbda_t, lmbda_t_1, r_lmbda_t_1):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  beta: numpy.array, shape = (n_features, )\n",
        "        primal optimal parameters vector\n",
        "\n",
        "  theta: numpy.array, shape = (n_features, )\n",
        "         dual optimal parameters vector\n",
        "\n",
        "  lmbda_t: float\n",
        "           regularization parameter at iteration t\n",
        "\n",
        "  lmbda_t_1: float\n",
        "             regularization parameter at iteration t-1\n",
        "  \n",
        "  r_lmbda_t_1: float\n",
        "               radius related to the regularization parameter lmbda_t_1\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  r_lmbda_t: float\n",
        "             radius related to the regularization parameter lmbda_t \n",
        "  \"\"\"\n",
        "\n",
        "  r_square_lmbda_t = (lmbda_t_1/lmbda_t)*r_lmbda_t_1**2 + (1 - lmbda_t/lmbda_t_1)*np.linalg.norm((X @ beta - y)/lmbda_t)**2 - (lmbda_t_1/lmbda_t - 1)*np.linalg.norm(theta)**2\n",
        "  r_lmbda_t = np.sqrt(r_square_lmbda_t)\n",
        "\n",
        "  return r_lmbda_t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91PnNP1rsbw7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 18 : Gap Safe Sphere\n",
        "\n",
        "def gap_safe_sphere(theta_k, r_lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  theta_k: numpy.array, shape = (n_features,)\n",
        "           dual optimal parameters vector\n",
        "  \n",
        "  r_lmbda: float\n",
        "           radius related to the regularization parameter lmbda\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  C_k: interval\n",
        "       sphere of center theta_k and of radius r_lmbda\n",
        "  \"\"\"\n",
        "\n",
        "  inf_bound = theta_k - r_lmbda\n",
        "  sup_bound = theta_k + r_lmbda\n",
        "  C_k = interval[inf_bound, sup_bound]\n",
        "  \n",
        "  return C_k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keF9Mj6LyTTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def R_primal(X, y, beta, lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  \n",
        "  X: numpy.ndarray, shape=(n_samples, n_features)\n",
        "     features matrix\n",
        "\n",
        "  y: numpy.array, shape=(n_samples, )\n",
        "     target labels vector \n",
        "\n",
        "  beta: numpy.array, shape=(n_features, )\n",
        "        primal optimal parameters vector\n",
        "\n",
        "  lmbda: float\n",
        "         regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  R_hat_lmbda: float\n",
        "               primal radius of the dome\n",
        "  \"\"\"\n",
        "\n",
        "  R_hat_lmbda = (1/lmbda)*np.max(np.linalg.norm(y)**2 - np.linalg.norm(np.dot(X, beta) - y)**2 - 2*lmbda*np.linalg.norm(beta, 1), 0)**(1/2)\n",
        "\n",
        "  return R_hat_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GL46v0ncTII",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJGmXOnmcVX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2f8b599e-2927-400c-84ee-6cba6264f7f8"
      },
      "source": [
        "R_hat_lmbda = R_primal(X, y, beta, lmbda)\n",
        "\n",
        "print(\"R primal (R_hat_lmbda) : \\n\", R_hat_lmbda)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R primal (R_hat_lmbda) : \n",
            " 3464.8358952601366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zci0OfYHzsNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def R_dual(y, theta, lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  \n",
        "  y: numpy.array, shape=(n_samples, ) \n",
        "     target labels vector \n",
        "\n",
        "  theta: numpy.array, shape=(n_features, )\n",
        "        dual optimal parameters vector\n",
        "\n",
        "  lmbda: float\n",
        "         regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  R_inv_hat_lmbda: float\n",
        "                   dual radius of the dome\n",
        "  \"\"\"\n",
        "\n",
        "  R_inv_hat_lmbda = np.linalg.norm(theta - y/lmbda)\n",
        "\n",
        "  return R_inv_hat_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceac9P_ecsNc",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGACeMlHcuEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7882e510-2c85-4431-e3c9-eab3c6bd63c6"
      },
      "source": [
        "R_inv_hat_lmbda = R_dual(y, theta_k, lmbda)\n",
        "\n",
        "print(\"R dual (R_inv_hat_lmbda) : \\n\", R_inv_hat_lmbda)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R dual (R_inv_hat_lmbda) : \n",
            " 3479.259836114735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9quLJwEi4ve4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def radius_thm2(R_hat_lmbda, R_inv_hat_lmbda):\n",
        "  \"\"\"Compute the radius of the safe sphere region\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  R_hat_lmbda: float \n",
        "               primal radius of the safe dome region\n",
        "\n",
        "  R_inv_hat_lmbda: float\n",
        "                   dual radius of the safe dome region\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  r_lmbda: float\n",
        "           radius of the safe sphere region\n",
        "  \"\"\"\n",
        "\n",
        "  r_lmbda = np.sqrt(R_inv_hat_lmbda**2 - R_hat_lmbda**2)\n",
        "\n",
        "  return r_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P50lvXov55f4",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abAoO_1w56-T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0565e140-84eb-4964-b7b8-9f9b1964df69"
      },
      "source": [
        "r_lmbda = radius_thm2(R_hat_lmbda, R_inv_hat_lmbda)\n",
        "\n",
        "print(\"Radius of the safe sphere region r_lmbda : \\n\", r_lmbda)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Radius of the safe sphere region r_lmbda : \n",
            " 316.4825842254526\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUoc5wkKxWoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 19 : Gap Safe Dome\n",
        "def gap_safe_dome(y, lmbda, theta_k, beta_k, R_hat_lmbda, R_inv_hat_lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ---------\n",
        "\n",
        "  y: np.array, shape = (n_samples, )\n",
        "\n",
        "  lmbda: float \n",
        "         regularization parameter\n",
        "  \n",
        "  theta_k: np.array, shape = (n_features, )\n",
        "           dual optimal parameters vector\n",
        "\n",
        "  beta_k: np.array, shape = (n_features, )\n",
        "          primal optimal parameters vector\n",
        "  \n",
        "  R_hat_lmbda: float\n",
        "               primal radius of the dome\n",
        "\n",
        "  R_inv_hat_lmbda: float\n",
        "                   dual radius of the dome\n",
        "  \n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  C_k: interval\n",
        "       gape safe dome\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  c_k = ((y/lmbda) + theta_k)/2\n",
        "  r_k = R_inv_hat_lmbda/2\n",
        "  sphere_k = interval[c_k - r_k, c_k + r_k]\n",
        "\n",
        "  alpha_k = 2*(R_hat_lmbda/R_inv_hat_lmbda)**2 - 1\n",
        "  w_k = (theta_k - y/lmbda)/np.linalg.norm(theta_k - y/lmbda)\n",
        "\n",
        "  margin_k = - alpha_k*r_k*w_k\n",
        "\n",
        "  # c_k - alpah_k*r_k*w_k is the projection of the ball center c on the hyperplane\n",
        "  # c = ball center\n",
        "  # r = ball radius\n",
        "  # oriented hyperplane with unit normal vector w and parameter alpha \n",
        "  # such that c - alpha*r*w is the projection of c on the hyperplane\n",
        "\n",
        "  C_k = sphere_k.intersection(margin_k) # problÃ¨me d'intersection avec l'hyperplane\n",
        "\n",
        "  return C_k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQc8HFRW8ZHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigma_support_function(x_j, theta):\n",
        "  \"\"\"Support Function\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  x_j: np.array, shape = (n_samples, )\n",
        "       vector of samples for a given feature j\n",
        "\n",
        "  theta: np.array, shape = (n_samples, )\n",
        "         vector of parameters \n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  sigma: float\n",
        "         scalar product <x, theta> between the j^th feature X[:,j] \n",
        "         and the vector of parameters theta\n",
        "  \"\"\"\n",
        "  sigma = -np.dot(x_j.T, theta)\n",
        "  \n",
        "  return sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHrikFTdBdWX",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ-_rIFXBVjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_1 = X[:,1]\n",
        "theta = np.random.randn(x_1.shape[0])\n",
        "sigma = sigma_support_function(x_1, theta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXfEeCqs-pa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigma_C(x_j, theta):\n",
        "  \"\"\"Support Function\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  x_j: np.array, shape = (n_samples, )\n",
        "       vector of samples for a given feature j  \n",
        "\n",
        "  theta: np.array, shape = (n_samples, )\n",
        "         vector of parameters\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  support_function: float\n",
        "                    maximum value of the scalar product between\n",
        "                    the j^th feature X[:,j] and the vector of parameters theta\n",
        "                    over the convex set C \n",
        "  \"\"\"\n",
        "  support_function = minimize(sigma_support_function, x_j, theta, method='nelder-mead', options={'xatol': 1e-8, 'disp': True})\n",
        "  support_function = -support_function\n",
        "  return support_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o6PTwgS8GSI",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XAmMs8l8Ii4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a6a74f34-506f-4cbc-cc50-55b633044f6f"
      },
      "source": [
        "%%time\n",
        "x_1 = X[:,1]\n",
        "theta = np.random.randn(x_1.shape[0])\n",
        "sigma = sigma_support_function(x_1, theta)\n",
        "# support_function = sigma_C(x_1, theta)\n",
        "print(sigma)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "30.922503744184503\n",
            "CPU times: user 201 Âµs, sys: 985 Âµs, total: 1.19 ms\n",
            "Wall time: 2.68 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRzJdP1e9lbO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mu_C(x_j, theta):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  x_j: np.array, shape = (n_samples, )\n",
        "       feature x_j \n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  mu: float \n",
        "      maximum between two sigma_C(x_j) and sigma_C(-x_j)\n",
        "  \"\"\"\n",
        "\n",
        "  # mu = max(sigma_C(x_j, theta), sigma_C(-x_j, theta))\n",
        "  mu = max(sigma_support_function(x_j, theta), sigma_support_function(-x_j, theta))\n",
        "\n",
        "  return mu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GNuV2EkEPno",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSfY3Bd0ERvC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "028af63f-b998-4628-ab04-e24584fed62f"
      },
      "source": [
        "mu = mu_C(x_1, theta)\n",
        "\n",
        "print(\"mu C : \\n\", mu) # ProblÃ¨me d'optimiseur "
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mu C : \n",
            " 30.922503744184503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjD5o6m5QRqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mu_B(x_j, c, r):\n",
        "  \"\"\"Function mu applied to the sphere of center c and radius r \n",
        "     for the j^th feature X[:,j]\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  x_j: numpy.array, shape=(n_samples, )\n",
        "       j^th feature X[:,j]\n",
        "\n",
        "  c: float\n",
        "     center of the sphere\n",
        "     \n",
        "  r: float\n",
        "     radius of the sphere\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  mu: float\n",
        "      maximum value between the scalar products of theta and x_j\n",
        "      and theta and -x_j\n",
        "  \"\"\"\n",
        "\n",
        "  mu = abs(np.dot(x_j.T, c)) + r*np.linalg.norm(x_j)\n",
        "\n",
        "  return mu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcbTSpbjR-wU",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3RWh_CZSDEO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5759442e-b002-42e4-aa68-a450a74bd34d"
      },
      "source": [
        "x_1 = X[:,1]\n",
        "c = np.random.randn(x_1.shape[0])\n",
        "r = 1\n",
        "mu = mu_B(x_1, c, r)\n",
        "\n",
        "print(\"mu value : \\n\", mu)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mu value : \n",
            " 63.81002868883159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph4uQljp7d19",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 7 : Active Set\n",
        "def active_set_vs_zero_set(X):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  X: numpy.ndarray, shape = (n_samples, n_features)\n",
        "     features matrix \n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  A_C: numpy.array, shape = (n_idx_active_features, )\n",
        "       active set : contains the indices of the relevant features\n",
        "  \n",
        "  Z_C: numpy.array, shape = (n_idx_zero_features, )\n",
        "       zero set : contains the indices of the irrelevant features\n",
        "  \"\"\"\n",
        "\n",
        "  theta = np.random.randn(x_1.shape[0]) # Initialisation ? \n",
        "  A_C = []\n",
        "  Z_C = []\n",
        "  p = X.shape[1]\n",
        "  for j in range(p):\n",
        "    mu = mu_C(X[:,j], theta)\n",
        "    if mu >= 1:\n",
        "      A_C.append(j)\n",
        "    else:\n",
        "      Z_C.append(j)\n",
        "\n",
        "  return A_C, Z_C"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzMzi0DYLwgw",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez_W8H7ALx9a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "adcf8d40-d709-4637-a247-d80b0fa48f7b"
      },
      "source": [
        "A_C, Z_C = active_set_vs_zero_set(X)\n",
        "\n",
        "print(\"Active Set : \\n\", A_C)\n",
        "print(\"Zero Set : \\n\", Z_C)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Active Set : \n",
            " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
            "Zero Set : \n",
            " [27]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2c2W7mbi-pI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sign(x):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  x: float\n",
        "     \n",
        "  Returns\n",
        "  -------\n",
        "  s: sign int\n",
        "     (-1) if x < 0,, (+1) if x > 0, 0 if x = 0\n",
        "  \"\"\"\n",
        "\n",
        "  if x > 0:\n",
        "    s = 1\n",
        "  elif x < 0:\n",
        "    s = -1\n",
        "  else:\n",
        "    s = 0\n",
        "\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtdBNZvFPUSD",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6Tq4TH_PWbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 2\n",
        "s = sign(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry19OgPy9qJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def soft_thresholding(u,x):\n",
        "  \"\"\"\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  u: float\n",
        "     threshold\n",
        "\n",
        "  x: float\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  ST: float\n",
        "      0 between -u and +u or slope of the straight line x - u otherwise \n",
        "      \n",
        "  \"\"\"\n",
        "\n",
        "  ST = sign(x)*np.max(np.abs(x) - u, 0)\n",
        "\n",
        "\n",
        "  return ST"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRPtCqAiPdM_",
        "colab_type": "text"
      },
      "source": [
        "## Test Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azbXVoHKPc7x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "u = 1\n",
        "ST = soft_thresholding(u,x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EceRmIc8nKcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Equation 1 : Primal Problem \n",
        "def primal_pb(X, y, beta, lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  X: numpy.ndarray, shape = (n_samples, n_features)\n",
        "     features matrix\n",
        "\n",
        "  y: numpy.array, shape = (n_samples, )\n",
        "     target labels vector\n",
        "\n",
        "  beta: numpy.array, shape = (n_features, )\n",
        "        initial vector of primal parameters\n",
        "\n",
        "  lmbda: float\n",
        "         regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  beta_hat_lmbda: numpy.array shape = (n_features, )\n",
        "                  primal optimal parameters vector\n",
        "  \"\"\"\n",
        "\n",
        "  P_lmbda = (1/2)*np.linalg.norm(np.dot(X, beta) - y, 2)**2 + lmbda*np.linalg.norm(beta, 1)\n",
        "\n",
        "  return beta_hat_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6drbIXq_6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dual_pb(y, theta, lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "  y: numpy.array, shape = (n_features, )\n",
        "\n",
        "  theta: numpy.array, shape = (n_features, )\n",
        "         initial vector of dual parameters\n",
        "\n",
        "  lmbda: float\n",
        "         regularization parameter\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  theta_hat_lmbda: numpy.array, shape = (n_features, )\n",
        "                   dual optimal parameters vector\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  D_lmbda = (1/2)*np.linalg.norm(y, ord=2)**2 - ((lmbda**2)/2)*np.linalg.norm(theta - y/lmbda, ord=2)**2\n",
        "  \n",
        "  return theta_hat_lmbda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFdRVITul7go",
        "colab_type": "text"
      },
      "source": [
        "## Maximization of the dual problem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO9QNioTmASW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "8a104042-f778-4541-fa02-64476239a3e0"
      },
      "source": [
        "def cyclic_coordinate_descent(X, y, lmbda, n_iter=10):\n",
        "    \"\"\"Solver : cyclic coordinate descent \n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "\n",
        "    X: numpy.ndarray, shape (n_samples, n_features)\n",
        "       features matrix\n",
        "\n",
        "    y: numpy.array, shape (n_samples, )\n",
        "       target labels vector\n",
        "\n",
        "    lmbda: float\n",
        "           regularization parameter\n",
        "\n",
        "    n_iter: int, default = 10\n",
        "            number of iterations  \n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "\n",
        "    theta: numpy.array, shape(n_features,)\n",
        "           dual parameters vector\n",
        "\n",
        "    all_objs: numpy.array, shape(n_features)\n",
        "              residuals vector\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialisation of the parameters\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "    all_objs = []\n",
        "\n",
        "    theta = np.zeros(n_features)\n",
        "    residuals = theta - y/lmbda\n",
        "\n",
        "    # Computation of the lipschitz constants vector \n",
        "\n",
        "    lips_const = np.linalg.norm(X, axis=0)**2\n",
        "\n",
        "    # Iterations of the algorithm\n",
        "    for k in range(n_iter):\n",
        "\n",
        "        # One cyclicly updates the i^{th} coordinate corresponding to the rest \n",
        "        # in the Euclidean division by the number of features \n",
        "        # This allows to always selecting an index between 1 and n_features\n",
        "        i = k % n_features + 1\n",
        "\n",
        "        old_theta_i = theta[i].copy()\n",
        "        if abs(np.dot(X[:,i].T, y/lmbda)) <= 1:\n",
        "          step = 1/lips_const[i] \n",
        "          reg = old_theta_i * X[:,i]\n",
        "          grad = (X[:,i].T).dot(residuals + reg)\n",
        "\n",
        "          # Update of the parameters\n",
        "          theta[i] += step*grad \n",
        "\n",
        "        # Update of the residuals\n",
        "        residuals += np.dot(X[:,i], old_beta_i - beta[i])\n",
        "\n",
        "        if k % n_features == 0:\n",
        "            # If k % n_features == 0 then we have updated all the coordinates\n",
        "            # This means that we have performed a whole cycle \n",
        "            # One computes the objective function \n",
        "            all_objs.append((residuals**2).sum()/2.)\n",
        "\n",
        "    return beta, np.array(all_objs)       \n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-6b25ae366d2c>\"\u001b[0;36m, line \u001b[0;32m53\u001b[0m\n\u001b[0;31m    step = 1/lips_const[i]\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0CMBVOPmuO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def duality_gap(beta_hat_lmbda, theta_hat_lmbda):\n",
        "  \"\"\"\n",
        "  Parameters\n",
        "  ----------\n",
        "\n",
        "  beta_hat_lmbda: numpy.array shape = (n_features, )\n",
        "                  primal optimal parameters vector\n",
        "\n",
        "  theta_hat_lmbda: numpy.array, shape = (n_features, )\n",
        "                   dual optimal parameters vector\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  G_lmbda: float\n",
        "           duality gap between the primal optimal and the dual optimal\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  G_lmbda = beta_hat_lmbda - theta_hat_lmbda\n",
        "\n",
        "  return G_lmbda\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq3JkhBXFvKK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cd_with_gap_safe_rules(X, y, epsilon, K, f, lmbda, T, lmbda_max):\n",
        "  \"\"\"Coordinate descent with gap safe rules \n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  X: numpy.ndarray, shape = (n_samples, n_features)\n",
        "     features matrix\n",
        "\n",
        "  y: numpy.array, shape = (n_features, )\n",
        "     target labels vector\n",
        "\n",
        "  epsilon: float \n",
        "           accuracy\n",
        "\n",
        "  T: int\n",
        "     number of epochs\n",
        "\n",
        "  K: int\n",
        "     number of iterations\n",
        "\n",
        "  f: int\n",
        "     frequency\n",
        "\n",
        "  lmbda: numpy.array, shape = (T-1, )\n",
        "          regularization parameters vector\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "\n",
        "  beta_lmbda_t: numpy.array, shape = (n_features, )\n",
        "                primal optimal parameters vector \n",
        "                for the regularization parameter lmbda at iteration t\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialization \n",
        "  lmbda = []\n",
        "  lmbda[0] = lmbda_max\n",
        "  beta = dict()\n",
        "  beta[\"lmbda0\"] = 0\n",
        "\n",
        "  for t in range(T-1):\n",
        "    beta = beta[\"lambda\" & (t-1)]\n",
        "\n",
        "    for k in range(K):\n",
        "      if k % f == 1:\n",
        "\n",
        "        # Computation of theta \n",
        "        # Equation 11\n",
        "        # Equation 18\n",
        "        # Equation 19\n",
        "        if G_lmbda(beta, theta) <= epsilon:\n",
        "          beta_lmbda = beta\n",
        "          break\n",
        "\n",
        "        for j in A_C:\n",
        "          beta_j = soft_thresholding(lmbda_t/np.linalg.norm(X[:,j])**2, beta_j - ((X[:,j].T @ (X @ beta - y))/np.linalg.norm(X[:,j])**2)\n",
        "\n",
        "  return beta_lmbda_t"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}